{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyPXiYbBH0uGiXkZdj2oOaQk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SomeiLam/api-docs-ai-agent-colab/blob/main/sikka_apis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Summary\n",
        "\n",
        "This Colab notebook implements a full‑stack, retrieval‑augmented code generation pipeline for building payment integration apps using Sikka APIs. It breaks the user’s high‑level request into discrete AI agents that each handle one piece of the workflow:\n",
        "\n",
        "1. **Query Optimizer**  \n",
        "   Normalizes and scopes the user’s message, detects tech stacks, and produces structured prompts.  \n",
        "2. **API‑Docs Generator**  \n",
        "   Retrieves relevant API reference snippets via FAISS and generates detailed endpoint documentation (base URL, version, headers, parameters, sample requests/responses).  \n",
        "3. **Frontend Code Generator**  \n",
        "   Produces React (or Next.js) components for the checkout UI, wiring up form state, loading, and error handling.  \n",
        "4. **Backend Code Generator**  \n",
        "   Generates Node.js + Express routes that obtain/refresh the Sikka `request_key`, save cards, and process payments.  \n",
        "5. **Code Evaluator & Refinement**  \n",
        "   Splits evaluation into frontend/backend reviewers, collects issues and suggestions, and applies fixes via a reusable refinement agent.  \n",
        "6. **Documentation Formatter**  \n",
        "   Assembles the optimized query, tech stack, API docs, frontend code, and backend code into a polished Markdown deliverable.  \n",
        "7. **Follow‑up QA**  \n",
        "   Maintains conversational memory and combines the final document with FAISS‑retrieved context to answer user follow‑up questions without re‑running the full pipeline.\n",
        "\n",
        "Together, these agents demonstrate how to orchestrate multiple LLM calls in Colab—leveraging CrewAI, FAISS, and OpenAI’s GPT models—to automate everything from requirements analysis to production‑ready code and documentation.\n",
        "\n",
        "---\n",
        "\n",
        "### Notebook Installation\n",
        "\n",
        "Before running any cells, install and pin your dependencies for a reproducible environment. In a new Colab cell, run\n",
        "```\n",
        "# Install core libraries for FAISS vector search, OpenAI API access, tokenization, agent orchestration, and retrieval workflows\n",
        "!pip install --upgrade --no-cache-dir \\\n",
        "    faiss-cpu    # vector similarity search engine for nearest‑neighbor lookup  \n",
        "    openai       # official OpenAI Python client for embeddings and chat completions  \n",
        "    tiktoken     # high‑speed tokenizer compatible with OpenAI models  \n",
        "    langchain    # framework for building retrieval‑augmented LLM applications  \n",
        "    crewai       # library for coordinating multi‑agent AI workflows  \n",
        "```"
      ],
      "metadata": {
        "id": "7OohWzNbognk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u3OYvvALXrY",
        "outputId": "732db07a-d74f-4ea7-91f1-545b232a6926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.75.0)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Collecting crewai\n",
            "  Downloading crewai-0.114.0-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting appdirs>=1.4.4 (from crewai)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting auth0-python>=4.7.1 (from crewai)\n",
            "  Downloading auth0_python-4.9.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.9.0)\n",
            "Collecting chromadb>=0.5.23 (from crewai)\n",
            "  Downloading chromadb-1.0.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from crewai) (8.1.8)\n",
            "Collecting instructor>=1.3.3 (from crewai)\n",
            "  Downloading instructor-1.7.9-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting json-repair>=0.25.2 (from crewai)\n",
            "  Downloading json_repair-0.41.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting json5>=0.10.0 (from crewai)\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting jsonref>=1.1.0 (from crewai)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting litellm==1.60.2 (from crewai)\n",
            "  Downloading litellm-1.60.2-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from crewai) (3.1.5)\n",
            "Requirement already satisfied: opentelemetry-api>=1.30.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.32.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http>=1.30.0 (from crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.30.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.32.1)\n",
            "Collecting pdfplumber>=0.11.4 (from crewai)\n",
            "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=1.0.0 (from crewai)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting pyvis>=0.3.2 (from crewai)\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tomli-w>=1.1.0 (from crewai)\n",
            "  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting tomli>=2.0.2 (from crewai)\n",
            "  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting uv>=0.4.25 (from crewai)\n",
            "  Downloading uv-0.6.14-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (3.11.15)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (8.6.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (4.23.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (0.21.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: cryptography>=43.0.1 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (43.0.3)\n",
            "Requirement already satisfied: pyjwt>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (2.10.1)\n",
            "Requirement already satisfied: urllib3>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (2.3.0)\n",
            "Collecting build>=1.0.3 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi==0.115.9 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m197.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.15.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (9.1.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (3.10.16)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (13.9.4)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb>=0.5.23->crewai)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (0.16)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (2.33.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.5->crewai) (2.0.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.30.0->crewai) (1.2.18)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai)\n",
            "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-proto==1.32.1->opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (5.29.4)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.30.0->crewai) (0.53b1)\n",
            "Collecting pdfminer.six==20250327 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m221.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber>=0.11.4->crewai) (3.4.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (4.0.5)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (3.4.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (1.19.0)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=43.0.1->auth0-python>=4.7.1->crewai) (1.17.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.30.0->crewai) (1.17.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm==1.60.2->crewai) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis>=0.3.2->crewai)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.60.2->crewai) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (1.13.1)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb>=0.5.23->crewai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb>=0.5.23->crewai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.23->crewai) (3.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm==1.60.2->crewai) (0.30.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.5.23->crewai) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (15.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=43.0.1->auth0-python>=4.7.1->crewai) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.60.2->crewai) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.60.2->crewai) (2025.3.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.23->crewai) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (0.6.1)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m283.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m425.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crewai-0.114.0-py3-none-any.whl (285 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.5/285.5 kB\u001b[0m \u001b[31m365.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litellm-1.60.2-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m182.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading auth0_python-4.9.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m188.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.0.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m262.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m371.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m319.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m226.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading instructor-1.7.9-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m310.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.6/345.6 kB\u001b[0m \u001b[31m387.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.41.1-py3-none-any.whl (21 kB)\n",
            "Downloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.32.1-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m125.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m210.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m295.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m415.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m389.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
            "Downloading uv-0.6.14-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m306.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m332.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m376.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m286.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m277.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m283.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m171.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m355.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m431.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m204.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m201.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m377.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m243.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m261.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53800 sha256=7878c5e96041c571e2cc364d2562efe487de8d49d08741e450bce667cd237120\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-38jlqdlp/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, appdirs, uvloop, uvicorn, uv, tomli-w, tomli, python-dotenv, pyproject_hooks, pypdfium2, overrides, opentelemetry-util-http, opentelemetry-proto, mmh3, jsonref, json5, json-repair, jiter, jedi, humanfriendly, httptools, faiss-cpu, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, tiktoken, starlette, posthog, opentelemetry-exporter-otlp-proto-common, httpx, coloredlogs, build, pyvis, pdfminer.six, onnxruntime, kubernetes, fastapi, auth0-python, pdfplumber, opentelemetry-instrumentation, litellm, instructor, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, crewai\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.9.0\n",
            "    Uninstalling jiter-0.9.0:\n",
            "      Successfully uninstalled jiter-0.9.0\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.10.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed appdirs-1.4.4 asgiref-3.8.1 auth0-python-4.9.0 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-1.0.5 coloredlogs-15.0.1 crewai-0.114.0 durationpy-0.9 faiss-cpu-1.10.0 fastapi-0.115.9 httptools-0.6.4 httpx-0.27.2 humanfriendly-10.0 instructor-1.7.9 jedi-0.19.2 jiter-0.8.2 json-repair-0.41.1 json5-0.12.0 jsonref-1.1.0 kubernetes-32.0.1 litellm-1.60.2 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.21.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-exporter-otlp-proto-http-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-util-http-0.53b1 overrides-7.7.0 pdfminer.six-20250327 pdfplumber-0.11.6 posthog-3.25.0 pypdfium2-4.30.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.0 pyvis-0.3.2 starlette-0.45.3 tiktoken-0.9.0 tomli-2.2.1 tomli-w-1.2.0 uv-0.6.14 uvicorn-0.34.1 uvloop-0.21.0 watchfiles-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --no-cache-dir faiss-cpu openai tiktoken langchain crewai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This initialization cell prepares our Colab environment by:\n",
        "\n",
        "- **Importing standard libraries**  \n",
        "  - `os`, `pathlib` for file and environment management  \n",
        "  - `json`, `pickle` for data serialization  \n",
        "  - `textwrap` for text formatting  \n",
        "  - `getpass` for optional secure input  \n",
        "  - `typing` helpers (`List`, `Dict`) for clearer function signatures  \n",
        "\n",
        "- **Importing core third‑party packages**  \n",
        "  - `numpy` for numerical arrays  \n",
        "  - `faiss` for fast similarity search over embeddings  \n",
        "  - `tiktoken` for tokenizing inputs to OpenAI models  \n",
        "  - `openai` for interacting with OpenAI’s embeddings and chat APIs  \n",
        "\n",
        "- **Loading your OpenAI API key securely**  \n",
        "  - Go to the Colab toolbar, click the **lock icon (Secrets pane)** on the left, choose **“Add secret”**, enter **`OPENAI_API_KEY`** as the name and paste your key as the value.  \n",
        "  - This makes it available via `from google.colab import userdata` and `userdata.get(\"OPENAI_API_KEY\")`.  \n",
        "\n",
        "- **Setting the embedding model**  \n",
        "  - `EMBED_MODEL = \"text-embedding-3-small\"` will be used for all vectorization calls.  \n",
        "\n",
        "With these steps, the notebook can safely call the OpenAI and FAISS-based vector search functions without exposing your secret in plain code.\n"
      ],
      "metadata": {
        "id": "SgK9kXoBuhsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pathlib\n",
        "import textwrap\n",
        "import pickle\n",
        "import getpass\n",
        "from typing import List, Dict\n",
        "\n",
        "import numpy as np\n",
        "import faiss\n",
        "import tiktoken\n",
        "import openai\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load the OpenAI API key from Colab secrets and set it as an environment variable\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "# Name of the embedding model to use for vectorization\n",
        "EMBED_MODEL = \"text-embedding-3-small\"\n"
      ],
      "metadata": {
        "id": "_I9m4P5vLc6E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines and runs a **`collect_docs`** function to extract structured documentation from the Postman collection JSON:\n",
        "\n",
        "1. **Loading & Parsing**  \n",
        "   - Reads `sikka-apis.json` into `root`.\n",
        "\n",
        "2. **Depth‑First Traversal**  \n",
        "   - Uses a stack to walk through nested dicts and lists.\n",
        "   - Tracks the “path” (e.g. `Sikka API v4 › Authorization › Generate request_key`) to locate each item.\n",
        "\n",
        "3. **Extracting Snippets**  \n",
        "   - Gathers:\n",
        "     - Plain-text `description` fields.\n",
        "     - Request-level docs & raw JSON bodies.\n",
        "     - Sample responses (`response.body`).\n",
        "     - Inline scripts (`event → script.exec`).\n",
        "\n",
        "4. **Output Format**  \n",
        "   - Returns a list of dicts, each with:\n",
        "     - `\"content\"`: a markdown string combining the snippets.\n",
        "     - `\"path\"`: the hierarchical breadcrumb.\n",
        "\n",
        "5. **Role in Pipeline**  \n",
        "   - These extracted docs become the **knowledge base** for FAISS indexing and subsequent retrieval‑augmented LLM prompts.\n"
      ],
      "metadata": {
        "id": "vS7BYu4pvRy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and parse the Postman collection JSON file\n",
        "FILE = pathlib.Path(\"sikka-apis.json\")   # Path to the raw API spec\n",
        "root = json.loads(FILE.read_text())      # Parse JSON into Python object\n",
        "\n",
        "def collect_docs(node):\n",
        "    \"\"\"\n",
        "    Traverse a Postman collection (dicts & lists) depth‑first, extracting:\n",
        "      - Resource & request descriptions\n",
        "      - Endpoint (METHOD + full URL)\n",
        "      - Headers\n",
        "      - Request body\n",
        "      - Response samples\n",
        "      - Example scripts\n",
        "\n",
        "    Returns a list of {\"content\": markdown, \"path\": hierarchical name}.\n",
        "    \"\"\"\n",
        "    stack, out = [([], node)], []\n",
        "\n",
        "    while stack:\n",
        "        path, cur = stack.pop()\n",
        "\n",
        "        if isinstance(cur, dict):\n",
        "            name     = cur.get(\"name\") or \"<no‑name>\"\n",
        "            new_path = path + [name]\n",
        "            buckets  = []\n",
        "\n",
        "            # 1) Resource‑level description\n",
        "            if desc := cur.get(\"description\"):\n",
        "                buckets.append(\"**Description:**\\n\" + desc.strip())\n",
        "\n",
        "            # 2) Request block\n",
        "            req    = cur.get(\"request\", {}) or {}\n",
        "            method = req.get(\"method\", \"\").upper()\n",
        "\n",
        "            # Build the full URL (either raw or protocol + host + path)\n",
        "            raw_url = req.get(\"url\", {}).get(\"raw\")\n",
        "            if not raw_url and isinstance(req.get(\"url\"), dict):\n",
        "                u = req[\"url\"]\n",
        "                host = \".\".join(u.get(\"host\", []))\n",
        "                path = \"/\".join(u.get(\"path\", []))\n",
        "                raw_url = f\"{u.get('protocol','https')}://{host}/{path}\"\n",
        "\n",
        "            # 2a) Request‑level description\n",
        "            if rdesc := req.get(\"description\"):\n",
        "                buckets.append(\"**Request Description:**\\n\" + rdesc.strip())\n",
        "\n",
        "            # 2b) Endpoint line\n",
        "            if method and raw_url:\n",
        "                buckets.append(f\"**Endpoint:** `{method} {raw_url}`\")\n",
        "\n",
        "            # 2c) Headers\n",
        "            if hdrs := req.get(\"header\"):\n",
        "                lines = [\n",
        "                    f\"- `{h.get('key')}`: `{h.get('value')}`\"\n",
        "                    for h in hdrs\n",
        "                ]\n",
        "                buckets.append(\"**Headers:**\\n\" + \"\\n\".join(lines))\n",
        "\n",
        "            # 2d) Request body\n",
        "            if raw_body := req.get(\"body\", {}).get(\"raw\"):\n",
        "                buckets.append(\n",
        "                    \"**Request Body:**\\n```json\\n\"\n",
        "                    + raw_body[:2000]\n",
        "                    + \"\\n```\"\n",
        "                )\n",
        "\n",
        "            # 3) Response samples\n",
        "            for resp in cur.get(\"response\", []):\n",
        "                status = resp.get(\"code\") or resp.get(\"status\", \"\")\n",
        "                if body := resp.get(\"body\"):\n",
        "                    label = f\"**Response ({status})**\" if status else \"**Response**\"\n",
        "                    buckets.append(\n",
        "                        f\"{label}:\\n```json\\n\"\n",
        "                        + body[:2000]\n",
        "                        + \"\\n```\"\n",
        "                    )\n",
        "\n",
        "            # 4) Event scripts (tests/examples)\n",
        "            for ev in cur.get(\"event\", []):\n",
        "                exec_lines = ev.get(\"script\", {}).get(\"exec\") or []\n",
        "                if exec_lines:\n",
        "                    buckets.append(\n",
        "                        \"**Example Script:**\\n```javascript\\n\"\n",
        "                        + \"\\n\".join(exec_lines)[:2000]\n",
        "                        + \"\\n```\"\n",
        "                    )\n",
        "\n",
        "            # If we have any extracted pieces, save them\n",
        "            if buckets:\n",
        "                out.append({\n",
        "                    \"content\": (\n",
        "                        f\"# {' › '.join(new_path)}\\n\\n\"\n",
        "                        + \"\\n\\n\".join(buckets)\n",
        "                    ),\n",
        "                    \"path\": \" › \".join(new_path)\n",
        "                })\n",
        "\n",
        "            # Recurse into child items\n",
        "            for child in cur.get(\"item\", []):\n",
        "                stack.append((new_path, child))\n",
        "\n",
        "        elif isinstance(cur, list):\n",
        "            for itm in cur:\n",
        "                stack.append((path, itm))\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "# Run the collector and show a quick summary\n",
        "docs = collect_docs(root)\n",
        "print(\"Total docs captured:\", len(docs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atx7CSq4LeXi",
        "outputId": "782f50fc-fad4-4bb9-8e66-48ce4d858cce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total docs captured: 392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell configures and demonstrates how to split raw documentation entries into manageable chunks for embedding and retrieval:\n",
        "\n",
        "- **Importing text splitters**  \n",
        "  - `RecursiveCharacterTextSplitter` (general‑purpose, prioritizes paragraphs and lines)  \n",
        "  - `MarkdownTextSplitter` (optional, preserves markdown headings and fenced code)  \n",
        "\n",
        "- **Configuring the splitter**  \n",
        "  - `chunk_size=3000` characters target  \n",
        "  - `chunk_overlap=150` characters overlap to boost retrieval recall  \n",
        "  - `separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]` to split on paragraphs, then lines, then words  \n",
        "\n",
        "- **Defining `smart_chunk_docs(docs)`**  \n",
        "  - Iterates over each doc entry  \n",
        "  - Uses the splitter to break `content` into `pieces`  \n",
        "  - Attaches metadata `{ \"path\": ..., \"chunk\": index }` to each piece  \n",
        "\n",
        "- **Demonstration**  \n",
        "  - `docs_raw = collect_docs(root)` gathers ~392 full entries  \n",
        "  - `docs_chunk = smart_chunk_docs(docs_raw)` produces ~517 chunks  \n",
        "  - Prints before/after counts and an example metadata dict  \n",
        "\n",
        "- **Role in Pipeline**  \n",
        "  Splitting ensures each chunk is small enough (<3000 chars) for embedding models while maintaining context, improving FAISS similarity search for downstream prompt construction.  \n"
      ],
      "metadata": {
        "id": "qzp8Tn80wl1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownTextSplitter\n",
        "\n",
        "# NOTE: We’re not using smart_chunk_docs here because our collected docs\n",
        "# are already well‑structured and sized appropriately for embedding.\n",
        "# In general, for unstructured text, you could split into ~3k‑char chunks:\n",
        "# splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=150, separators=[\"\\n\\n\",\"\\n\",\" \",\"\"])\n",
        "# or use MarkdownTextSplitter to preserve headings/code fences.\n",
        "#\n",
        "# But for our Postman‑derived docs, each entry is its own “chunk” and passed\n",
        "# directly to the embedder.\n",
        "\n",
        "def smart_chunk_docs(docs):\n",
        "    \"\"\"\n",
        "    (Optional) Split large docs into overlapping sub‑chunks for retrieval.\n",
        "    Not used in this pipeline since each doc entry is already appropriately sized.\n",
        "    \"\"\"\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=3000,\n",
        "        chunk_overlap=150,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "    )\n",
        "    out = []\n",
        "    for d in docs:\n",
        "        pieces = splitter.split_text(d[\"content\"])\n",
        "        meta   = d.get(\"meta\") or {\"path\": d.get(\"path\", \"\")}\n",
        "        for i, part in enumerate(pieces):\n",
        "            out.append({\"content\": part, \"meta\": {**meta, \"chunk\": i}})\n",
        "    return out\n",
        "\n",
        "# Use the raw docs directly for embedding/retrieval:\n",
        "docs_raw = collect_docs(root)         # e.g. 392 entries\n",
        "print(\"Docs to index:\", len(docs_raw))\n",
        "docs_chunk = smart_chunk_docs(docs_raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWGnlDYsLg3L",
        "outputId": "48fc7de0-829c-4fe3-aef9-8e1989ba3712"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Docs to index: 392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell builds our FAISS vector index by embedding each documentation chunk:\n",
        "\n",
        "- **Client setup**  \n",
        "  - Uses the `OpenAI` client with your `api_key` for embedding calls.  \n",
        "\n",
        "- **Defining `embed_texts`**  \n",
        "  - Wrapper around the new OpenAI ≥1.0.0 SDK  \n",
        "  - Takes a list of strings plus an embedding model name  \n",
        "  - Returns a list of float vectors in the same order as inputs  \n",
        "\n",
        "- **Batch embedding loop**  \n",
        "  - Splits `docs_raw` into batches of size 96  \n",
        "  - Calls `embed_texts` for each batch to avoid rate or size limits  \n",
        "  - Accumulates all embeddings into `vecs`  \n",
        "\n",
        "- **FAISS index creation**  \n",
        "  - Converts `vecs` to a NumPy array of type `float32`  \n",
        "  - Initializes an inner‑product index (`IndexFlatIP`) matching the embedding dimension  \n",
        "  - Adds all vectors to the index for fast similarity search  \n",
        "\n",
        "- **Verification**  \n",
        "  - Prints the total number of vectors indexed (`index.ntotal`)  \n",
        "\n",
        "This prepares the FAISS index for nearest‑neighbor retrieval in downstream prompt construction.\n"
      ],
      "metadata": {
        "id": "jnnHZB_vxNDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "def embed_texts(texts: list[str], model: str = EMBED_MODEL) -> list[list[float]]:\n",
        "    \"\"\"\n",
        "    Returns embeddings for a list of texts using the OpenAI SDK client.\n",
        "    \"\"\"\n",
        "    resp = client.embeddings.create(model=model, input=texts)\n",
        "    return [e.embedding for e in resp.data]\n",
        "\n",
        "# Batch‑embed all raw document chunks and build a FAISS index\n",
        "vecs, BATCH = [], 96\n",
        "for i in range(0, len(docs_raw), BATCH):\n",
        "    batch = [d[\"content\"] for d in docs_raw[i:i+BATCH]]\n",
        "    vecs.extend(embed_texts(batch))\n",
        "\n",
        "# Convert to NumPy float32 array and index with inner‑product similarity\n",
        "vecs = np.asarray(vecs, dtype=\"float32\")\n",
        "index = faiss.IndexFlatIP(vecs.shape[1])\n",
        "index.add(vecs)\n",
        "\n",
        "print(\"FAISS index size:\", index.ntotal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fku7VWSLiDc",
        "outputId": "be47b931-d1c5-4a47-f316-5618fed75b69"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index size: 392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**  \n",
        "\n",
        "This helper function lets you query the raw Sikka API documentation “knowledge base” without triggering the full pipeline. It:\n",
        "\n",
        "- **Embeds the user query**  \n",
        "  - Calls `embed_texts` to get the query vector  \n",
        "- **Performs a FAISS lookup**  \n",
        "  - Retrieves the top `k` most similar document chunks  \n",
        "- **Builds a minimal LLM prompt**  \n",
        "  - System instruction: “Answer only from context; say ‘Not found’ otherwise.”  \n",
        "  - User message: includes the retrieved context and the original question  \n",
        "- **Invokes the chat model**  \n",
        "  - Uses `gpt-4o-mini` and returns the assistant’s text response  \n",
        "\n",
        "You can call `ask_sikka(\"your question\")` to test how well the vector store + LLM answers direct questions from the docs.\n"
      ],
      "metadata": {
        "id": "TZpM5eZFx_Nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_sikka(\n",
        "    query: str,\n",
        "    k: int = 4,\n",
        "    model: str = \"gpt-4o-mini\",\n",
        "    debug: bool = False\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Retrieve the top‑k relevant chunks for `query` from your FAISS index,\n",
        "    then ask the chat model to answer using ONLY that context.\n",
        "\n",
        "    Args:\n",
        "      query: The user’s question.\n",
        "      k: Number of chunks to retrieve.\n",
        "      model: Which chat model to use.\n",
        "      debug: If True, print each retrieved chunk with its score.\n",
        "\n",
        "    Returns:\n",
        "      The assistant’s reply (stripped of whitespace).\n",
        "    \"\"\"\n",
        "    # 1) Embed the query\n",
        "    embedding: List[float] = embed_texts([query])[0]\n",
        "\n",
        "    # 2) FAISS search for top-k similar docs\n",
        "    distances, indices = index.search(\n",
        "        np.array([embedding], dtype=\"float32\"),\n",
        "        k\n",
        "    )\n",
        "\n",
        "    # 3) Debug output of retrieved snippets\n",
        "    if debug:\n",
        "        for dist, idx in zip(distances[0], indices[0]):\n",
        "            snippet = docs_chunk[idx][\"content\"]\n",
        "            print(f\"[DEBUG] Chunk {idx} (score {dist:.3f}):\\n{snippet}\\n\")\n",
        "\n",
        "    # 4) Build the context string\n",
        "    context = \"\\n\\n---\\n\\n\".join(\n",
        "        docs_chunk[i][\"content\"] for i in indices[0]\n",
        "    )\n",
        "\n",
        "    # 5) Ask the model with a strict “only-from-context” instruction\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"Answer **only** from the context below; if it's not in the context, reply 'Not found'.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Context:\\n{context}\\n\\nQuestion: {query}\"\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 6) Return the assistant’s reply\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "\n",
        "# ── Example Usage ─────────────────────────────────────────────────────\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    for q in [\n",
        "        \"For the POST /v2/payment/store-card endpoint, list its headers and parameters.\",\n",
        "        \"What is the endpoint for save a card?\"\n",
        "    ]:\n",
        "        print(f\"Q: {q}\")\n",
        "        print(\"A:\", ask_sikka(q))\n",
        "        # print(\"A:\", ask_sikka(q, debug=True))\n",
        "        print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "90WpqVXALj7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfea42bc-198e-41e7-f64e-e74ee8658a26"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: For the POST /v2/payment/store-card endpoint, list its headers and parameters.\n",
            "A: Not found.\n",
            "----------------------------------------\n",
            "Q: What is the endpoint for save a card?\n",
            "A: The endpoint for saving a card is `POST https://api.sikkasoft.com/v2/payment/store_card`.\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines the `OPTIMIZER_TEMPLATE` string, which primes the Query Optimizer Agent to:\n",
        "\n",
        "- **Validate Scope**  \n",
        "  - Checks if the user’s request pertains to building or integrating with Sikka APIs.  \n",
        "  - If out‑of‑scope, instructs the agent to output a minimal JSON and stop.\n",
        "\n",
        "- **Detect Tech Stack**  \n",
        "  - Parses the user message for frontend frameworks/languages (e.g. React, Next.js, TypeScript).  \n",
        "  - Parses for backend frameworks/languages (e.g. Node.js, Express, Python, Flask).  \n",
        "  - Falls back to “React + JavaScript” front end and “Node.js + Express + JavaScript” back end if none are detected.\n",
        "\n",
        "- **Rewrite & Decompose**  \n",
        "  - Produces a one‑sentence `optimized_query` restating the user’s goal.  \n",
        "  - Generates **four** specialized prompts under `prompts` for downstream agents:\n",
        "    1. **api_docs** – Instructs how to identify and document all required Sikka endpoints, including full base URLs, auth flow, headers, parameters, and examples.  \n",
        "    2. **frontend** – Guides the UI agent to build the frontend with the detected framework, integrate the endpoints, and handle state/loading/errors.  \n",
        "    3. **backend** – Directs the backend agent to implement routes in the detected framework, handle `request_key` acquisition/refresh, and call the endpoints returning JSON.  \n",
        "    4. **formatter** – Tells the formatter agent to assemble everything into a single Markdown document with specified headings.\n",
        "\n",
        "- **Define JSON Output Schema**  \n",
        "  - Specifies the exact structure the optimizer must return, containing:  \n",
        "    ```json\n",
        "    {\n",
        "      \"scope_ok\": true|false,\n",
        "      \"optimized_query\": \"...\",\n",
        "      \"tech_stack\": {\"frontend\": \"...\", \"backend\": \"...\"},\n",
        "      \"prompts\": {\n",
        "        \"api_docs\": \"...\",\n",
        "        \"frontend\": \"...\",\n",
        "        \"backend\": \"...\",\n",
        "        \"formatter\": \"...\"\n",
        "      }\n",
        "    }\n",
        "    ```  \n",
        "  - Emphasizes “no extra keys” to ensure downstream agents receive a strictly consistent payload.\n"
      ],
      "metadata": {
        "id": "5wjUY7o48mhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt template  ─────────────────────────────────────────────\n",
        "\n",
        "OPTIMIZER_TEMPLATE = \"\"\"\n",
        "You are the Query Optimizer for a multi‑agent system that builds full‑stack apps with Sikka APIs.\n",
        "\n",
        "USER_MESSAGE:\n",
        "\\\"\\\"\\\"{user_message}\\\"\\\"\\\"\n",
        "\n",
        "Step 1: Scope\n",
        "• If the message is not about building or integrating Sikka APIs, output exactly:\n",
        "  {{ \"scope_ok\": false, \"reason\": \"short explanation\" }}\n",
        "  and STOP.\n",
        "\n",
        "Step 2: Tech stack\n",
        "• Detect any frontend frameworks/languages (e.g. React, Next.js, TypeScript).\n",
        "• Detect any backend frameworks/languages (e.g. Node.js, Express, Python, Flask).\n",
        "• If none are found, default to “React + JavaScript” front end and “Node.js + Express + JavaScript” back end.\n",
        "\n",
        "Step 3: Rewrite & decompose\n",
        "• Produce one sentence `optimized_query` restating the goal.\n",
        "• Produce **four** prompts under `prompts` with these keys:\n",
        "\n",
        "  1. **api_docs**\n",
        "     – Identify all required Sikka endpoints for `optimized_query`.\n",
        "     – For each endpoint, specify the **full base URL including version** (e.g. `https://api.sikkasoft.com/v4`), the path, and HTTP method.\n",
        "     – Document the authentication flow (request_key lifecycle).\n",
        "     – List required headers and body/query parameters per endpoint.\n",
        "     – Include a sample request and a sample response for each endpoint.\n",
        "\n",
        "  2. **frontend**\n",
        "     – Build the UI using the detected frontend framework.\n",
        "     – Call the endpoints identified in `api_docs`.\n",
        "     – Specify component/file names.\n",
        "     – Handle form state, loading indicators, and error displays.\n",
        "\n",
        "  3. **backend**\n",
        "     – Implement server routes using the detected backend framework.\n",
        "     – Include code to obtain and refresh the request_key.\n",
        "     – Show how to call each Sikka endpoint and return JSON responses.\n",
        "\n",
        "  4. **formatter**\n",
        "     – Assemble **all** outputs into a single Markdown document.\n",
        "     – Include headings for Overview, API Documentation, Frontend Code, and Backend Code.\n",
        "\n",
        "Step 4: Output exactly this JSON (no extra keys):\n",
        "\n",
        "```json\n",
        "{{\n",
        "  \"scope_ok\": true,\n",
        "  \"optimized_query\": \"<one‑sentence restatement>\",\n",
        "  \"tech_stack\": {{\n",
        "    \"frontend\": \"<detected or default stack>\",\n",
        "    \"backend\":  \"<detected or default stack>\"\n",
        "  }},\n",
        "  \"prompts\": {{\n",
        "    \"api_docs\":  \"<instruction containing all required elements>\",\n",
        "    \"frontend\":  \"<instruction containing all required elements>\",\n",
        "    \"backend\":   \"<instruction containing all required elements>\",\n",
        "    \"formatter\": \"<instruction containing all required elements>\"\n",
        "  }}\n",
        "}}\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "b9Xn1yBwLkyi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell sets up and runs the **Query Optimizer** agent:\n",
        "\n",
        "- **Imports & Client Setup**  \n",
        "  - `Agent`, `Task`, `Crew` from `crewai` to define and execute tasks.  \n",
        "  - `re` for stripping Markdown fences from the LLM output.  \n",
        "  - `OpenAI` client (v1 SDK) initialized with the Colab secret.  \n",
        "\n",
        "- **Agent Definition**  \n",
        "  - Creates `optimizer_agent` with role, goal, backstory, and LLM spec (`gpt-4o-mini`).  \n",
        "  - Defines a reusable `opt_task` template pointing at `OPTIMIZER_TEMPLATE`.  \n",
        "\n",
        "- **Helper Function `run_optimizer`**  \n",
        "  1. **Prompt Formatting**  \n",
        "     - Injects the `user_message` into the `OPTIMIZER_TEMPLATE`.  \n",
        "  2. **Task Execution**  \n",
        "     - Constructs and runs a one‑task `Crew` to invoke the optimizer.  \n",
        "  3. **Output Cleaning**  \n",
        "     - Strips any ```json fences.  \n",
        "  4. **JSON Parsing**  \n",
        "     - Returns a Python `dict` matching the optimizer’s schema.  \n",
        "\n",
        "- **Example Invocation**  \n",
        "  - Demonstrates using `run_optimizer(...)` to validate/normalize a sample user request.\n"
      ],
      "metadata": {
        "id": "98-QnuP185Hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from crewai import Agent, Task, Crew\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load API key from Colab secrets and initialize OpenAI client\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# 1) Define the Query Optimizer agent\n",
        "optimizer_agent = Agent(\n",
        "    role=\"Query Optimizer\",\n",
        "    goal=\"Validate scope and normalize user queries about Sikka APIs\",\n",
        "    backstory=\"Expert in Sikka’s API portfolio and software design.\",\n",
        "    allow_delegation=False,\n",
        "    llm=\"gpt-4o-mini\"\n",
        ")\n",
        "\n",
        "# 2) Prepare the optimization task template\n",
        "opt_task = Task(\n",
        "    agent=optimizer_agent,\n",
        "    description=OPTIMIZER_TEMPLATE,    # will .format(user_message=…) later\n",
        "    expected_output=\"JSON exactly matching the schema above.\"\n",
        ")\n",
        "\n",
        "def run_optimizer(user_message: str) -> dict:\n",
        "    \"\"\"\n",
        "    Execute the optimizer on `user_message` and parse its JSON output.\n",
        "    \"\"\"\n",
        "    # a) Inject the user's message into the template\n",
        "    prompt = OPTIMIZER_TEMPLATE.format(user_message=user_message)\n",
        "\n",
        "    # b) Create & run the task\n",
        "    task = Task(\n",
        "        agent=optimizer_agent,\n",
        "        description=prompt,\n",
        "        expected_output=\"JSON exactly matching the schema above.\"\n",
        "    )\n",
        "    crew_output = Crew(agents=[optimizer_agent], tasks=[task], verbose=False).kickoff()\n",
        "\n",
        "    # c) Extract raw LLM response\n",
        "    raw = crew_output.tasks_output[0].raw\n",
        "\n",
        "    # d) Strip any ``` or ```json fences\n",
        "    cleaned = \"\\n\".join(\n",
        "        line for line in raw.splitlines()\n",
        "        if not re.match(r\"^```(?:json)?\\s*$\", line)\n",
        "    ).strip()\n",
        "\n",
        "    # e) Parse and return as a dict\n",
        "    return json.loads(cleaned)\n",
        "\n",
        "# Example: Using the Query Optimizer on a user request\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Define the user's natural‑language request\n",
        "    user_request = (\n",
        "        \"I want a React checkout page that saves a patient's card \"\n",
        "        \"and runs a $25 sale using the Sikka sandbox.\"\n",
        "    )\n",
        "\n",
        "    # 2) Print the original request string\n",
        "    print(\"=== User Request ===\")\n",
        "    print(user_request, \"\\n\")\n",
        "\n",
        "    # 3) Run the optimizer to normalize & decompose the request\n",
        "    optimized_output = run_optimizer(user_request)\n",
        "\n",
        "    # 4) Pretty‑print the optimized result for clarity\n",
        "    import json\n",
        "    print(\"=== Optimizer Result ===\")\n",
        "    print(json.dumps(optimized_output, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2ILqBcFLlzS",
        "outputId": "ae5fa671-152a-441d-e1d2-4eb71ecfa907"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== User Request ===\n",
            "I want a React checkout page that saves a patient's card and runs a $25 sale using the Sikka sandbox. \n",
            "\n",
            "=== Optimizer Result ===\n",
            "{\n",
            "  \"scope_ok\": true,\n",
            "  \"optimized_query\": \"Create a React checkout page that saves a patient's card and processes a $25 sale using the Sikka sandbox.\",\n",
            "  \"tech_stack\": {\n",
            "    \"frontend\": \"React + JavaScript\",\n",
            "    \"backend\": \"Node.js + Express + JavaScript\"\n",
            "  },\n",
            "  \"prompts\": {\n",
            "    \"api_docs\": \"Identify necessary Sikka endpoints for card saving and transaction processing. Include base URLs: 1. `https://api.sikkasoft.com/v4/cards` (POST) for saving card info. 2. `https://api.sikkasoft.com/v4/transactions` (POST) for processing the sale. Authentication will require a request_key, which must be obtained through a secure flow at app initialization. Required headers: `Content-Type: application/json`, `Authorization: Bearer <request_key>`. Sample request for saving card: {\\\"card_number\\\": \\\"1234567890123456\\\", \\\"expiration\\\": \\\"12/25\\\", \\\"cvv\\\": \\\"123\\\"}, and expected response: {\\\"status\\\": \\\"success\\\", \\\"message\\\": \\\"Card saved successfully\\\"}. For transaction: {\\\"amount\\\": 25, \\\"currency\\\": \\\"USD\\\", \\\"card_id\\\": \\\"<saved_card_id>\\\"}, with response: {\\\"status\\\": \\\"success\\\", \\\"transaction_id\\\": \\\"tx123456\\\"}.\",\n",
            "    \"frontend\": \"Develop a checkout component in React. Create a file named `Checkout.js`. Use `useState` for form handling and manage submission logic. Call the `/cards` endpoint to save card info and the `/transactions` endpoint to process the sale. Implement loading indicators and error handling for user feedback.\",\n",
            "    \"backend\": \"Set up an Express server. Create routes to manage API calls to Sikka endpoints. Obtain the request_key upon server start and refresh as needed. Route to save card data should handle POST requests to `/api/save-card` and /api/process-transaction for sales. Return JSON responses.\",\n",
            "    \"formatter\": \"Compile a Markdown document that includes an Overview of the app, detailed API Documentation, Frontend Code for the React checkout component, and Backend Code for the Express server implementation.\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell sets up and runs the “API‑Docs Generator” agent:\n",
        "\n",
        "- **Imports**  \n",
        "  - Pulls in `Agent`, `Task`, and `Crew` from `crewai` to define and execute the agent.  \n",
        "  - Imports `numpy` for array handling in the FAISS search.\n",
        "\n",
        "- **Context Retriever**  \n",
        "  - `retrieve_api_context(query, k)` embeds the user’s query, searches the FAISS index for the top‑k most relevant chunks, and concatenates them as a context string.\n",
        "\n",
        "- **Agent Definition**  \n",
        "  - `api_doc_agent` is configured to generate detailed Markdown API documentation for Sikka endpoints.\n",
        "\n",
        "- **Runner Function**  \n",
        "  - `run_api_docs_step(opt_out)`  \n",
        "    1. Checks if the user request is in‑scope.  \n",
        "    2. Builds a prompt combining the optimizer’s `api_docs` instruction with FAISS‑retrieved context.  \n",
        "    3. Runs a single‑task Crew to get the Markdown documentation.  \n",
        "    4. Returns the raw Markdown response for downstream use.\n"
      ],
      "metadata": {
        "id": "zV7RXdeY96bT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew   # Core classes to define and run our agent\n",
        "import numpy as np                    # Numerical library used by FAISS search\n",
        "\n",
        "def retrieve_api_context(query: str, k: int = 6) -> str:\n",
        "    \"\"\"\n",
        "    Embed the query, perform a FAISS similarity search,\n",
        "    and join the top-k document chunks into one context string.\n",
        "    \"\"\"\n",
        "    q_emb = embed_texts([query])[0]                      # 1) Create embedding for the query\n",
        "    _, idx = index.search(np.array([q_emb], dtype=\"float32\"), k)  # 2) Search FAISS index\n",
        "    # 3) Concatenate the retrieved passages with separators\n",
        "    return \"\\n\\n---\\n\\n\".join(docs[i][\"content\"] for i in idx[0])\n",
        "\n",
        "# Define the API‑Docs Generator agent\n",
        "api_doc_agent = Agent(\n",
        "    role             = \"API Docs Generator\",    # Agent’s persona\n",
        "    goal             = \"Produce detailed API documentation for the endpoints needed\",\n",
        "    backstory        = \"Specialist in Sikka API reference docs.\",\n",
        "    allow_delegation = False,\n",
        "    llm              = \"gpt-4o-mini\"\n",
        ")\n",
        "\n",
        "def run_api_docs_step(opt_out: dict) -> str:\n",
        "    \"\"\"\n",
        "    Build and run a single‑task Crew to generate Markdown API docs.\n",
        "    Returns the raw Markdown or an out‑of‑scope notice.\n",
        "    \"\"\"\n",
        "    # 1) Scope guard: skip if optimizer said out‑of‑scope\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return \"⚠️ Out of scope. No API docs generated.\"\n",
        "\n",
        "    # 2) Prepare prompt: instruction + retrieved context\n",
        "    instr  = opt_out[\"prompts\"][\"api_docs\"]                   # Optimizer’s API‑docs instruction\n",
        "    ctx    = retrieve_api_context(opt_out[\"optimized_query\"]) # FAISS context for the optimized query\n",
        "    prompt = f\"{instr}\\n\\nHere is the relevant API context:\\n{ctx}\"  # Complete LLM prompt\n",
        "\n",
        "    # 3) Define and run the Crew task\n",
        "    task = Task(\n",
        "        agent           = api_doc_agent,\n",
        "        description     = prompt,\n",
        "        expected_output = (\n",
        "            \"A Markdown document covering ONLY the Sikka endpoints, \"\n",
        "            \"authentication flow, headers, parameters, and sample calls.\"\n",
        "        )\n",
        "    )\n",
        "    crew_output = Crew(\n",
        "        agents=[api_doc_agent],\n",
        "        tasks=[task],\n",
        "        verbose=False\n",
        "    ).kickoff()  # Execute the task\n",
        "\n",
        "    # 4) Extract and return the raw Markdown response\n",
        "    return crew_output.tasks_output[0].raw\n"
      ],
      "metadata": {
        "id": "g-Csxg0uLsA1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines and runs the “Frontend Code Generator” agent:\n",
        "\n",
        "- **Agent Definition**  \n",
        "  - Creates `frontend_agent` with a React/Next.js focus and clear UI/UX expertise.\n",
        "\n",
        "- **Runner Function (`run_frontend_step`)**  \n",
        "  1. **Scope Guard:** Returns early if the optimizer flagged the request as out‑of‑scope.  \n",
        "  2. **Prompt Assembly:** Combines the optimizer’s “frontend” instruction with the previously generated API docs.  \n",
        "  3. **Crew Execution:** Spins up a one‑task Crew to generate the React/Next.js code.  \n",
        "  4. **Output Extraction:** Returns the raw code string for use by subsequent steps.\n"
      ],
      "metadata": {
        "id": "Qp4bW7cg-GR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# 1) Define the Frontend Code Generator agent\n",
        "frontend_agent = Agent(\n",
        "    role             = \"Frontend Code Generator\",              # Agent’s persona\n",
        "    goal             = \"Produce React/Next.js frontend code for the checkout flow\",\n",
        "    backstory        = \"Expert in building modern React applications and UI/UX best practices.\",\n",
        "    allow_delegation = False,\n",
        "    llm              = \"gpt-4o-mini\"                         # Model to drive this agent\n",
        ")\n",
        "\n",
        "def run_frontend_step(opt_out: dict, api_docs_md: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate (or regenerate) the React/Next.js frontend code.\n",
        "\n",
        "    Args:\n",
        "      opt_out     – Output dict from run_optimizer(...)\n",
        "      api_docs_md – Markdown API docs from run_api_docs_step(...)\n",
        "\n",
        "    Returns:\n",
        "      Raw code string for the frontend application.\n",
        "    \"\"\"\n",
        "    # 1) Out‑of‑scope guard\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return \"⚠️ Out of scope. No frontend code generated.\"\n",
        "\n",
        "    # 2) Build the prompt using the optimizer’s 'frontend' instruction\n",
        "    instr  = opt_out[\"prompts\"][\"frontend\"]                   # Instruction text\n",
        "    prompt = (\n",
        "        f\"{instr}\\n\\nHere are the API docs you should integrate with:\\n\"\n",
        "        f\"{api_docs_md}\"\n",
        "    )\n",
        "\n",
        "    # 3) Launch a one‑task Crew to generate the code\n",
        "    task = Task(\n",
        "        agent           = frontend_agent,                     # Which agent to run\n",
        "        description     = prompt,                             # Full LLM prompt\n",
        "        expected_output = (\n",
        "            \"A React (or Next.js) component/file structure & code for the checkout UI, \"\n",
        "            \"handling card input, form state, loading, and error display.\"\n",
        "        )\n",
        "    )\n",
        "    crew_output = Crew(\n",
        "        agents=[frontend_agent],\n",
        "        tasks =[task],\n",
        "        verbose=False\n",
        "    ).kickoff()\n",
        "\n",
        "    # 4) Extract and return the raw code string\n",
        "    return crew_output.tasks_output[0].raw\n"
      ],
      "metadata": {
        "id": "7nO57VoDLtoe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines and runs the “Backend Code Generator” agent:\n",
        "\n",
        "- **Agent Definition**  \n",
        "  - Creates `backend_agent` specialized in Node.js/Express APIs with a focus on security and scalability.\n",
        "\n",
        "- **Runner Function (`run_backend_step`)**  \n",
        "  1. **Scope Guard:** Checks the optimizer output; returns early if out‑of‑scope.  \n",
        "  2. **Prompt Assembly:** Combines the optimizer’s “backend” instruction with the generated API docs.  \n",
        "  3. **Crew Execution:** Launches a one‑task Crew to generate the Express server code.  \n",
        "  4. **Output Extraction:** Returns the raw backend code string for downstream use.  \n"
      ],
      "metadata": {
        "id": "WEQSxeY--Rpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# 1) Define the Backend Code Generator agent\n",
        "backend_agent = Agent(\n",
        "    role             = \"Backend Code Generator\",                 # Agent’s persona\n",
        "    goal             = \"Produce Node.js/Express backend code for the checkout flow\",\n",
        "    backstory        = \"Expert in building secure and scalable Express APIs.\",\n",
        "    allow_delegation = False,\n",
        "    llm              = \"gpt-4o-mini\"                          # Model to drive this agent\n",
        ")\n",
        "\n",
        "def run_backend_step(opt_out: dict, api_docs_md: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate the Node.js + Express backend code.\n",
        "\n",
        "    Args:\n",
        "      opt_out     – dict from run_optimizer(...)\n",
        "      api_docs_md – Markdown API docs from run_api_docs_step(...)\n",
        "\n",
        "    Returns:\n",
        "      Raw code string for the backend server.\n",
        "    \"\"\"\n",
        "    # 1) Out‑of‑scope guard\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return \"⚠️ Out of scope. No backend code generated.\"\n",
        "\n",
        "    # 2) Build the prompt using the optimizer’s 'backend' instruction\n",
        "    instr  = opt_out[\"prompts\"][\"backend\"]                      # Instruction text\n",
        "    prompt = (\n",
        "        f\"{instr}\\n\\nHere are the API docs you should integrate with:\\n\"\n",
        "        f\"{api_docs_md}\"\n",
        "    )\n",
        "\n",
        "    # 3) Launch a one‑task Crew to generate the code\n",
        "    task = Task(\n",
        "        agent           = backend_agent,                         # Which agent to run\n",
        "        description     = prompt,                                # Full LLM prompt\n",
        "        expected_output = (\n",
        "            \"Node.js + Express server code with routes to handle saving cards \"\n",
        "            \"and processing payments using the provided Sikka endpoints.\"\n",
        "        )\n",
        "    )\n",
        "    crew_output = Crew(\n",
        "        agents=[backend_agent],\n",
        "        tasks =[task],\n",
        "        verbose=False\n",
        "    ).kickoff()\n",
        "\n",
        "    # 4) Extract and return the raw code string\n",
        "    return crew_output.tasks_output[0].raw\n"
      ],
      "metadata": {
        "id": "U1kkqOVDLu68"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines the **Frontend Code Evaluator** agent and its runner function:\n",
        "\n",
        "- **Agent Definition**  \n",
        "  - `frontend_evaluator_agent` is a specialist in React/Next.js best practices and front‑end security.  \n",
        "  - Its sole responsibility is to detect **critical** correctness or security issues.\n",
        "\n",
        "- **Runner Helper (`run_frontend_eval`)**  \n",
        "  1. **Scope Check:** Returns empty report if the request is out of scope.  \n",
        "  2. **Prompt Construction:** Crafts a strict JSON‑only prompt asking for issues and suggestions.  \n",
        "  3. **Crew Execution:** Runs a single‑task Crew to evaluate the provided code.  \n",
        "  4. **Fence Stripping:** Removes any Markdown code fences from the LLM response.  \n",
        "  5. **JSON Parsing:** Parses and returns the structured report for downstream use.\n"
      ],
      "metadata": {
        "id": "yfbH6NWm-rhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# 1) Define the Frontend Evaluator agent\n",
        "frontend_evaluator_agent = Agent(\n",
        "    role             = \"Frontend Code Evaluator\",                  # Agent’s persona\n",
        "    goal             = (\n",
        "        \"Inspect the React/Next.js frontend code and report *only* critical \"\n",
        "        \"correctness or security issues in JSON format.\"\n",
        "    ),\n",
        "    backstory        = \"Expert in React best practices, form validation, and front‑end security.\",\n",
        "    allow_delegation = False,\n",
        "    llm              = \"gpt-4o-mini\"                               # Model to drive evaluation\n",
        ")\n",
        "\n",
        "# 2) Runner helper for frontend evaluation\n",
        "def run_frontend_eval(opt_out: dict, frontend_code: str) -> dict:\n",
        "    \"\"\"\n",
        "    Analyze frontend code for blocking issues and return a JSON report:\n",
        "    {\n",
        "      \"issues\": [ {\"location\":\"frontend\",\"line\":int,\"message\":str,\"severity\":\"critical\"}, ... ],\n",
        "      \"suggestions\": [ str, ... ]\n",
        "    }\n",
        "    \"\"\"\n",
        "    # Guard: skip evaluation if out-of-scope\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return {\"issues\": [], \"suggestions\": []}\n",
        "\n",
        "    # Build a strict JSON‑schema prompt\n",
        "    prompt = f\"\"\"\n",
        "You are a strict Bug‑Finder focused ONLY on frontend code.\n",
        "Report *only* critical correctness or security issues in this JSON schema:\n",
        "\n",
        "{{\n",
        "  \"issues\": [\n",
        "    {{\n",
        "      \"location\": \"frontend\",\n",
        "      \"line\": <integer>,\n",
        "      \"message\": \"<description>\",\n",
        "      \"severity\": \"critical\"\n",
        "    }},\n",
        "    ...\n",
        "  ],\n",
        "  \"suggestions\": [\n",
        "    \"<actionable improvement>\",\n",
        "    ...\n",
        "  ]\n",
        "}}\n",
        "\n",
        "Here is the frontend code to evaluate:\n",
        "{frontend_code}\n",
        "\n",
        "Do NOT include any markdown or additional keys—output only the JSON.\n",
        "\"\"\".strip()\n",
        "\n",
        "    # Execute the evaluation task\n",
        "    task = Task(\n",
        "        agent           = frontend_evaluator_agent,\n",
        "        description     = prompt,\n",
        "        expected_output = \"A JSON object with keys 'issues' and 'suggestions'.\"\n",
        "    )\n",
        "    out = Crew(agents=[frontend_evaluator_agent], tasks=[task], verbose=False).kickoff()\n",
        "    raw = out.tasks_output[0].raw                                 # Raw LLM reply\n",
        "\n",
        "    # Remove any ``` code fences\n",
        "    cleaned = \"\\n\".join(\n",
        "        line for line in raw.splitlines()\n",
        "        if not re.match(r\"^```(?:\\\\w+)?\\\\s*$\", line)\n",
        "    ).strip()\n",
        "\n",
        "    # Parse and return the JSON issue report\n",
        "    return json.loads(cleaned)\n"
      ],
      "metadata": {
        "id": "jLoK-cpvLwHF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines the **Backend Code Evaluator** agent and its runner function:\n",
        "\n",
        "- **Agent Definition**  \n",
        "  - `backend_evaluator_agent` is an expert in Express API design, authentication flows, and security.  \n",
        "  - Its sole responsibility is to identify **critical** correctness or security issues in backend code.\n",
        "\n",
        "- **Runner Helper (`run_backend_eval`)**  \n",
        "  1. **Scope Check:** Returns an empty report if the request is out of scope.  \n",
        "  2. **Prompt Construction:** Builds a strict JSON‑only prompt asking for backend issues and suggestions.  \n",
        "  3. **Crew Execution:** Runs a single‑task Crew to evaluate the provided backend code.  \n",
        "  4. **Fence Stripping:** Removes any Markdown code fences from the LLM response.  \n",
        "  5. **JSON Parsing:** Parses and returns the structured report for use in the refinement pipeline.\n"
      ],
      "metadata": {
        "id": "3weYgEGG-xPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# 1) Define the Backend Evaluator agent\n",
        "backend_evaluator_agent = Agent(\n",
        "    role             = \"Backend Code Evaluator\",                     # Agent persona\n",
        "    goal             = (\n",
        "        \"Inspect the Node.js/Express backend code and report *only* critical \"\n",
        "        \"correctness or security issues in JSON format.\"\n",
        "    ),\n",
        "    backstory        = \"Expert in Express API design, authentication flows, and backend security.\",\n",
        "    allow_delegation = False,\n",
        "    llm              = \"gpt-4o-mini\"                                 # Model for evaluation\n",
        ")\n",
        "\n",
        "# 2) Runner helper for backend evaluation\n",
        "def run_backend_eval(opt_out: dict, backend_code: str) -> dict:\n",
        "    \"\"\"\n",
        "    Analyze backend code for blocking issues.\n",
        "    Returns a dict with:\n",
        "      {\n",
        "        \"issues\": [\n",
        "          {\"location\":\"backend\",\"line\":int,\"message\":str,\"severity\":\"critical\"},\n",
        "          ...\n",
        "        ],\n",
        "        \"suggestions\": [\n",
        "          str, ...\n",
        "        ]\n",
        "      }\n",
        "    \"\"\"\n",
        "    # Guard: skip if out-of-scope\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return {\"issues\": [], \"suggestions\": []}\n",
        "\n",
        "    # Build a strict JSON‑schema prompt\n",
        "    prompt = f\"\"\"\n",
        "You are a strict Bug‑Finder focused ONLY on backend code.\n",
        "Report *only* critical correctness or security issues in this JSON schema:\n",
        "\n",
        "{{\n",
        "  \"issues\": [\n",
        "    {{\n",
        "      \"location\": \"backend\",\n",
        "      \"line\": <integer>,\n",
        "      \"message\": \"<description>\",\n",
        "      \"severity\": \"critical\"\n",
        "    }},\n",
        "    ...\n",
        "  ],\n",
        "  \"suggestions\": [\n",
        "    \"<actionable improvement>\",\n",
        "    ...\n",
        "  ]\n",
        "}}\n",
        "\n",
        "Here is the backend code to evaluate:\n",
        "{backend_code}\n",
        "\n",
        "Do NOT include any markdown or additional keys—output only the JSON.\n",
        "\"\"\".strip()\n",
        "\n",
        "    # Execute the evaluation task\n",
        "    task = Task(\n",
        "        agent           = backend_evaluator_agent,\n",
        "        description     = prompt,\n",
        "        expected_output = \"A JSON object with keys 'issues' and 'suggestions'.\"\n",
        "    )\n",
        "    out = Crew(agents=[backend_evaluator_agent], tasks=[task], verbose=False).kickoff()\n",
        "    raw = out.tasks_output[0].raw                                  # Raw LLM reply\n",
        "\n",
        "    # Remove any ``` code fences\n",
        "    cleaned = \"\\n\".join(\n",
        "        line for line in raw.splitlines()\n",
        "        if not re.match(r\"^```(?:\\\\w+)?\\\\s*$\", line)\n",
        "    ).strip()\n",
        "\n",
        "    # Parse and return the JSON report\n",
        "    return json.loads(cleaned)\n"
      ],
      "metadata": {
        "id": "0nawYk5eLxFD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines a **reusable Code Refinement Agent** and its helper function:\n",
        "\n",
        "- **Agent Definition**  \n",
        "  - `refine_agent` is an expert in iterative code improvement and best practices.  \n",
        "  - Its goal is to take evaluator feedback and produce a revised code snippet (frontend or backend) without any extra text.\n",
        "\n",
        "- **Runner Helper (`run_refine_step`)**  \n",
        "  1. **Scope Check:** Returns the original snippet if out of scope.  \n",
        "  2. **Feedback Preparation:** Converts suggestion strings into a bullet‑list (not used directly in prompt but illustrative).  \n",
        "  3. **Prompt Construction:** Includes the evaluator report and original code, asks for only the refined code.  \n",
        "  4. **Crew Execution:** Runs a single‑task Crew to generate the updated code.  \n",
        "  5. **Fence Stripping:** Removes any ``` code fences from the response.  \n",
        "  6. **Return:** Outputs the cleaned, refined code snippet.\n"
      ],
      "metadata": {
        "id": "_ERy8Wnj-3_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# 1) Define the Code Refinement Agent\n",
        "refine_agent = Agent(\n",
        "    role             = \"Code Refinement Agent\",        # Agent persona\n",
        "    goal             = (\n",
        "        \"Incorporate evaluator feedback into an existing code snippet \"\n",
        "        \"and return the revised code only.\"\n",
        "    ),\n",
        "    backstory        = \"Expert in iterative code improvement and best practices.\",\n",
        "    allow_delegation = False,                         # Keep tasks internal\n",
        "    llm              = \"gpt-4o-mini\"                  # Model to run refinements\n",
        ")\n",
        "\n",
        "def run_refine_step(\n",
        "    opt_out: dict,           # Output from the optimizer step\n",
        "    code_snippet: str,       # The code to refine (frontend or backend)\n",
        "    eval_report: dict,       # JSON with 'issues' and 'suggestions'\n",
        "    code_type: str           # \"frontend\" or \"backend\"\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Refine a code snippet by applying the evaluator's suggestions.\n",
        "    Returns only the updated code (no explanations).\n",
        "    \"\"\"\n",
        "    # 2) Out‑of‑scope guard\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return code_snippet\n",
        "\n",
        "    # 3) Build the prompt with evaluator report and original code\n",
        "    prompt = f\"\"\"\n",
        "You are a Code Refinement Agent. Update the following {code_type} code using the evaluator feedback.\n",
        "\n",
        "Evaluator Report:\n",
        "{json.dumps(eval_report, indent=2)}\n",
        "\n",
        "Original {code_type.capitalize()} Code:\n",
        "```\n",
        "{code_snippet}\n",
        "```\n",
        "\n",
        "Please return **only** the refined {code_type} code, applying all critical fixes. Do not include any explanations.\n",
        "\"\"\".strip()\n",
        "\n",
        "    # 4) Create and run the refinement task\n",
        "    task = Task(\n",
        "        agent           = refine_agent,\n",
        "        description     = prompt,\n",
        "        expected_output = f\"The updated {code_type} code snippet, with fixes applied.\"\n",
        "    )\n",
        "    crew_output = Crew(agents=[refine_agent], tasks=[task], verbose=False).kickoff()\n",
        "    raw = crew_output.tasks_output[0].raw  # LLM response\n",
        "\n",
        "    # 5) Strip any ``` code fences from the response\n",
        "    cleaned = \"\\n\".join(\n",
        "        line for line in raw.splitlines()\n",
        "        if not re.match(r\"^```(?:\\w+)?\\s*$\", line)\n",
        "    ).strip()\n",
        "\n",
        "    # 6) Return the cleaned, refined code\n",
        "    return cleaned\n"
      ],
      "metadata": {
        "id": "1RVUKkAZLyBk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines the **parallelized end‑to‑end pipelines** for both frontend and backend:\n",
        "\n",
        "- **`_pipeline_frontend`**  \n",
        "  1. **Generate** initial React code  \n",
        "  2. **Evaluate** it for critical issues (prints debug report)  \n",
        "  3. **Refine** the code if any blocking issues are found  \n",
        "  4. **Return** the final, possibly refined frontend snippet  \n",
        "\n",
        "- **`_pipeline_backend`**  \n",
        "  1. **Generate** initial Express code  \n",
        "  2. **Evaluate** it for critical issues (prints debug report)  \n",
        "  3. **Refine** the code if needed  \n",
        "  4. **Return** the final backend snippet  \n",
        "\n",
        "- **`run_frontend_and_backend`**  \n",
        "  - Uses `ThreadPoolExecutor` to run both pipelines **concurrently**  \n",
        "  - Returns a tuple: `(final_frontend_code, final_backend_code)`  \n",
        "\n",
        "By parallelizing, this cell speeds up the combined generation‑evaluate‑refine workflow for both layers.\n"
      ],
      "metadata": {
        "id": "0UOaxYru_UuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def _pipeline_frontend(opt_out: dict, api_docs_md: str) -> str:\n",
        "    \"\"\"\n",
        "    Full frontend pipeline: generate → evaluate → refine.\n",
        "    Returns the final refined frontend code.\n",
        "    \"\"\"\n",
        "    # 1) Generate initial React/Next.js code\n",
        "    code = run_frontend_step(opt_out, api_docs_md)\n",
        "\n",
        "    # 2) Evaluate for critical issues\n",
        "    eval_report = run_frontend_eval(opt_out, code)\n",
        "    print(\"[DEBUG] Frontend eval_report:\", eval_report, flush=True)\n",
        "\n",
        "    # 3) Refine if any critical issues were reported\n",
        "    if eval_report[\"issues\"]:\n",
        "        code = run_refine_step(opt_out, code, eval_report, code_type=\"frontend\")\n",
        "\n",
        "    return code\n",
        "\n",
        "def _pipeline_backend(opt_out: dict, api_docs_md: str) -> str:\n",
        "    \"\"\"\n",
        "    Full backend pipeline: generate → evaluate → refine.\n",
        "    Returns the final refined backend code.\n",
        "    \"\"\"\n",
        "    # 1) Generate initial Node.js/Express code\n",
        "    code = run_backend_step(opt_out, api_docs_md)\n",
        "\n",
        "    # 2) Evaluate for critical issues\n",
        "    eval_report = run_backend_eval(opt_out, code)\n",
        "    print(\"[DEBUG] Backend eval_report:\", eval_report, flush=True)\n",
        "\n",
        "    # 3) Refine if any critical issues were reported\n",
        "    if eval_report[\"issues\"]:\n",
        "        code = run_refine_step(opt_out, code, eval_report, code_type=\"backend\")\n",
        "\n",
        "    return code\n",
        "\n",
        "def run_frontend_and_backend(opt_out: dict, api_docs_md: str) -> tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Execute both frontend and backend pipelines in parallel.\n",
        "    Returns a tuple: (final_frontend_code, final_backend_code).\n",
        "    \"\"\"\n",
        "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "        fut_frontend = executor.submit(_pipeline_frontend, opt_out, api_docs_md)\n",
        "        fut_backend  = executor.submit(_pipeline_backend,  opt_out, api_docs_md)\n",
        "\n",
        "        final_frontend = fut_frontend.result()\n",
        "        final_backend  = fut_backend.result()\n",
        "\n",
        "    return final_frontend, final_backend"
      ],
      "metadata": {
        "id": "lpT1UB2yLzGj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines the **Formatter Agent** and its runner helper:\n",
        "\n",
        "- **`formatter_agent`**  \n",
        "  - An LLM agent tasked with assembling all pieces into one Markdown document  \n",
        "  - Has the role “Documentation Formatter” and a clear goal to produce sections in order  \n",
        "\n",
        "- **`run_formatter_step`**  \n",
        "  1. **Guard**: checks `scope_ok` before doing anything  \n",
        "  2. **Build Prompt**: embeds the optimized query, tech stack, API docs, frontend code, and backend code into a single instruction  \n",
        "  3. **Invoke** the `formatter_agent` via a one‑task `Crew`  \n",
        "  4. **Extract & Clean**: pulls out the raw Markdown and removes any accidental outer code fences  \n",
        "  5. **Return** the final Markdown string  \n",
        "\n",
        "With this, the system produces a cohesive document containing Overview, API Documentation, Frontend Code, and Backend Code sections.\n"
      ],
      "metadata": {
        "id": "vLn5I6f0_hCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# 1) Define the Formatter Agent\n",
        "formatter_agent = Agent(\n",
        "    role             = \"Documentation Formatter\",  # Agent’s title\n",
        "    goal             = (                             # What it must achieve\n",
        "        \"Assemble the optimized query, tech stack, API docs, frontend code, \"\n",
        "        \"and backend code into one coherent Markdown document.\"\n",
        "    ),\n",
        "    backstory        = \"Detail‑oriented technical writer and developer.\",\n",
        "    allow_delegation = False,                       # Don’t split into sub‑agents\n",
        "    llm              = \"gpt-4o-mini\"                # Model to use\n",
        ")\n",
        "\n",
        "def run_formatter_step(\n",
        "    opt_out: dict,\n",
        "    api_docs_md: str,\n",
        "    frontend_code: str,\n",
        "    backend_code: str\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Takes optimizer output plus API docs, frontend, and backend code,\n",
        "    and returns a single Markdown document with the correct sections.\n",
        "    \"\"\"\n",
        "    # Guard: only proceed if the original query was in‑scope\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return \"⚠️ Out of scope. Nothing to format.\"\n",
        "\n",
        "    # Build the instruction for the agent, injecting all pieces\n",
        "    prompt = f\"\"\"\n",
        "You are the Documentation Formatter. Using the pieces below, produce **only**\n",
        "a Markdown document with these top‑level headings in this order:\n",
        "\n",
        "# Overview\n",
        "# API Documentation\n",
        "# Frontend Code\n",
        "# Backend Code\n",
        "\n",
        "### Overview\n",
        "**Task:** {opt_out['optimized_query']}\n",
        "**Tech Stack:**\n",
        "- Frontend: {opt_out['tech_stack']['frontend']}\n",
        "- Backend: {opt_out['tech_stack']['backend']}\n",
        "\n",
        "### API Documentation\n",
        "{api_docs_md}\n",
        "\n",
        "### Frontend Code\n",
        "```javascript\n",
        "{frontend_code}\n",
        "```\n",
        "### Backend Code\n",
        "```javascript\n",
        "{backend_code}\n",
        "```\n",
        "Return only the Markdown—no extra commentary. \"\"\".strip()\n",
        "\n",
        "    # Create the formatting task\n",
        "    task = Task(\n",
        "        agent           = formatter_agent,\n",
        "        description     = prompt,\n",
        "        expected_output = \"A single Markdown document with the specified sections.\"\n",
        "    )\n",
        "    # Run the agent\n",
        "    crew_output = Crew(agents=[formatter_agent], tasks=[task], verbose=False).kickoff()\n",
        "\n",
        "    # Extract the raw Markdown response\n",
        "    md = crew_output.tasks_output[0].raw\n",
        "\n",
        "    # If the LLM wrapped everything in ``` fences, remove them\n",
        "    if md.startswith(\"```\"):\n",
        "        md = \"\\n\".join(line for line in md.splitlines() if not re.match(r\"^```\", line)).strip()\n",
        "\n",
        "    return md\n"
      ],
      "metadata": {
        "id": "AOjIMfm4PO0J"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell ties together the entire Sikka checkout AI pipeline and provides a CLI‑style entry point:\n",
        "\n",
        "- **`orchestrate(user_message)`**  \n",
        "  1. **Optimize** the user’s request into a structured plan (`opt_out`).  \n",
        "  2. **Generate API docs** based on that plan, showing only the first 300 characters as a snippet.  \n",
        "  3. **Produce & auto‑fix** both frontend and backend code in parallel, printing short snippets.  \n",
        "  4. **Format** all pieces into one cohesive Markdown document (`final_md`).  \n",
        "  5. **Return** the final Markdown (or an out‑of‑scope notice).\n",
        "\n",
        "- **Debug prints** at each stage help you trace progress in Colab or your terminal.\n",
        "\n",
        "- **`if __name__ == \"__main__\"`** block demonstrates how to call `orchestrate` directly when running the script, printing the complete output.\n",
        "\n",
        "With this cell, you can run the full end‑to‑end flow in one call and see live debug output for each step.\n"
      ],
      "metadata": {
        "id": "ldTXJg3m__e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def orchestrate(user_message: str) -> str:\n",
        "    \"\"\"\n",
        "    Runs the full Sikka checkout pipeline:\n",
        "      1) Optimize the user query\n",
        "      2) Generate API docs\n",
        "      3) Generate & auto‑fix frontend + backend code\n",
        "      4) Format everything into Markdown\n",
        "\n",
        "    Returns the final Markdown (or an out‑of‑scope notice).\n",
        "    \"\"\"\n",
        "    # 1) Optimize: parse and structure the user’s request\n",
        "    opt_out = run_optimizer(user_message)\n",
        "    print(\"🔍 Optimizer Output:\", opt_out, \"\\n\" + \"─\" * 60, flush=True)\n",
        "    # If out of scope, immediately return notice\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return f\"⚠️ Out of scope: {opt_out.get('reason','')}\"\n",
        "\n",
        "    # 2) API docs: generate documentation and show a snippet\n",
        "    api_docs = run_api_docs_step(opt_out)\n",
        "    print(\"📄 API Documentation (snippet):\", api_docs[:300], \"\\n\" + \"─\" * 60, flush=True)\n",
        "\n",
        "    # 3) Code gen & refinement: run both pipelines in parallel\n",
        "    frontend_code, backend_code = run_frontend_and_backend(opt_out, api_docs)\n",
        "    print(\"🚀 Frontend Code (snippet):\", frontend_code[:200], flush=True)\n",
        "    print(\"🔧 Backend  Code (snippet):\", backend_code[:200], \"\\n\" + \"─\" * 60, flush=True)\n",
        "\n",
        "    # 4) Formatting: assemble all parts into final Markdown\n",
        "    final_md = run_formatter_step(opt_out, api_docs, frontend_code, backend_code)\n",
        "    print(\"🎉 Final Markdown generated.\", flush=True)\n",
        "\n",
        "    # Return the complete Markdown document\n",
        "    return final_md\n",
        "\n",
        "# ── Example usage ───────────────────────────────────────────\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample user request to kick off the pipeline\n",
        "    message = (\n",
        "        \"I want a React checkout page that saves a patient's card \"\n",
        "        \"and runs a $25 sale using Sikka sandbox.\"\n",
        "    )\n",
        "    # Run orchestration and print the result\n",
        "    doc = orchestrate(message)\n",
        "    print(\"\\n=== Final Output ===\\n\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UrpwDkgL1Kx",
        "outputId": "24e151f2-5eeb-4a2b-f56a-11f4b5581e80"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Optimizer Output: {'scope_ok': True, 'optimized_query': \"Create a React checkout page that saves a patient's card and processes a $25 transaction using Sikka's sandbox environment.\", 'tech_stack': {'frontend': 'React + JavaScript', 'backend': 'Node.js + Express + JavaScript'}, 'prompts': {'api_docs': \"Identify required Sikka endpoints to create a payment method and process a payment. Main endpoints may include: 1) Save Payment Method: `https://api.sikkasoft.com/v4/payment_methods` (POST). Required authentication through a request_key. Headers: Authorization: Bearer <request_key>. Body: { 'patient_id': '123', 'card_data': { ... } }. Sample Request: { 'patient_id': '123', 'card_data': { 'number': '4111111111111111', 'expiration': '12/24', 'cvc': '123' } }. Sample Response: { 'success': true, 'method_id': 'abc123' }. 2) Process Payment: `https://api.sikkasoft.com/v4/payments` (POST). Headers: Authorization: Bearer <request_key>. Body: { 'method_id': 'abc123', 'amount': 25 }. Sample Request: { 'method_id': 'abc123', 'amount': 25 }. Sample Response: { 'success': true, 'transaction_id': 'txn789' }.\", 'frontend': 'Develop the checkout page using React. Create components: CheckoutForm.js, PaymentSuccess.js, PaymentError.js. Use useState to manage form data, include loading indicators while processing, and display error messages in case of failure. Call the Save Payment Method and Process Payment endpoints identified in api_docs from form submission.', 'backend': 'Set up Express.js routes to handle API calls. Create routes for /save_payment_method and /process_payment. Use middleware to obtain and refresh request_key. Use axios or fetch to call Sikka endpoints returning JSON responses. Ensure to handle errors and send appropriate responses back to the frontend.', 'formatter': 'Combine the outputs into a single Markdown document. Structure it with an Overview section explaining the functionality, an API Documentation section detailing endpoints and sample requests/responses, a Frontend Code section with React component code, and a Backend Code section with Express route implementations.'}} \n",
            "────────────────────────────────────────────────────────────\n",
            "📄 API Documentation (snippet): # Sikka Payments API Documentation\n",
            "\n",
            "## Overview\n",
            "The Sikka Payments API allows healthcare practices to securely process patient payments. This documentation covers the endpoints needed to create a payment method and process a payment.\n",
            "\n",
            "## Authentication Flow\n",
            "All requests to the Sikka Payments API req \n",
            "────────────────────────────────────────────────────────────\n",
            "[DEBUG] Backend eval_report: {'issues': [{'location': 'backend', 'line': 13, 'message': 'Hardcoded request_key is insecure and may lead to vulnerabilities.', 'severity': 'critical'}, {'location': 'backend', 'line': 55, 'message': 'Direct logging of error responses can expose sensitive data in logs.', 'severity': 'critical'}], 'suggestions': ['Implement a secure method to retrieve request_key, avoiding hardcoding.', 'Remove sensitive information from error logs or mask it before logging.']}\n",
            "[DEBUG] Frontend eval_report: {'issues': [{'location': 'frontend', 'line': 46, 'message': 'Hardcoded patient_id is a security risk; sensitive data should not be hardcoded.', 'severity': 'critical'}, {'location': 'frontend', 'line': 9, 'message': 'Auth token (requestKey) is hardcoded; consider using environment variables to avoid exposure.', 'severity': 'critical'}, {'location': 'frontend', 'line': 24, 'message': 'Card information (cardNumber, expiration, cvc) is stored in state without encryption; sensitive data should be handled securely.', 'severity': 'critical'}, {'location': 'frontend', 'line': 9, 'message': 'Lack of validation on sensitive input (CVC, card number); implement further validation to prevent malicious data.', 'severity': 'critical'}], 'suggestions': ['Remove hardcoded patient_id and pass it securely from a backend service.', 'Use environment variables to store sensitive tokens such as requestKey.', 'Implement encryption for sensitive information stored in state.', 'Add comprehensive validation for credit card information to enhance security.']}\n",
            "🚀 Frontend Code (snippet): // src/components/CheckoutForm.js\n",
            "import React, { useState } from 'react';\n",
            "import axios from 'axios';\n",
            "\n",
            "const CheckoutForm = ({ requestKey, patientId }) => {\n",
            "  const [cardNumber, setCardNumber] = useSt\n",
            "🔧 Backend  Code (snippet): const express = require('express');\n",
            "const axios = require('axios');\n",
            "const bodyParser = require('body-parser');\n",
            "const { getRequestKey } = require('./secureKeyProvider'); // Secure method to retrieve re \n",
            "────────────────────────────────────────────────────────────\n",
            "🎉 Final Markdown generated.\n",
            "\n",
            "=== Final Output ===\n",
            "\n",
            "# Overview\n",
            "**Task:** Create a React checkout page that saves a patient's card and processes a $25 transaction using Sikka's sandbox environment.  \n",
            "**Tech Stack:**\n",
            "- Frontend: React + JavaScript\n",
            "- Backend: Node.js + Express + JavaScript\n",
            "\n",
            "# API Documentation\n",
            "# Sikka Payments API Documentation\n",
            "\n",
            "## Overview\n",
            "The Sikka Payments API allows healthcare practices to securely process patient payments. This documentation covers the endpoints needed to create a payment method and process a payment.\n",
            "\n",
            "## Authentication Flow\n",
            "All requests to the Sikka Payments API require authentication using a `request_key`. This key should be included in the header of each API request.\n",
            "\n",
            "### Headers\n",
            "- **Authorization**: `Bearer <request_key>`\n",
            "- **Content-Type**: `application/json`\n",
            "\n",
            "## Endpoints\n",
            "\n",
            "### 1. Save Payment Method\n",
            "This endpoint allows you to save a payment method for a patient.\n",
            "\n",
            "- **Endpoint**: `POST https://api.sikkasoft.com/v4/payment_methods`\n",
            "- **Headers**:\n",
            "  - Authorization: Bearer \\<request_key\\>\n",
            "- **Body**:\n",
            "```json\n",
            "{\n",
            "  \"patient_id\": \"123\",\n",
            "  \"card_data\": {\n",
            "    \"number\": \"4111111111111111\",\n",
            "    \"expiration\": \"12/24\",\n",
            "    \"cvc\": \"123\"\n",
            "  }\n",
            "}\n",
            "```\n",
            "- **Sample Request**:\n",
            "```json\n",
            "{\n",
            "  \"patient_id\": \"123\",\n",
            "  \"card_data\": {\n",
            "    \"number\": \"4111111111111111\",\n",
            "    \"expiration\": \"12/24\",\n",
            "    \"cvc\": \"123\"\n",
            "  }\n",
            "}\n",
            "```\n",
            "- **Sample Response**:\n",
            "```json\n",
            "{\n",
            "  \"success\": true,\n",
            "  \"method_id\": \"abc123\"\n",
            "}\n",
            "```\n",
            "\n",
            "### 2. Process Payment\n",
            "This endpoint processes a payment using a saved payment method.\n",
            "\n",
            "- **Endpoint**: `POST https://api.sikkasoft.com/v4/payments`\n",
            "- **Headers**:\n",
            "  - Authorization: Bearer \\<request_key\\>\n",
            "- **Body**:\n",
            "```json\n",
            "{\n",
            "  \"method_id\": \"abc123\",\n",
            "  \"amount\": 25\n",
            "}\n",
            "```\n",
            "- **Sample Request**:\n",
            "```json\n",
            "{\n",
            "  \"method_id\": \"abc123\",\n",
            "  \"amount\": 25\n",
            "}\n",
            "```\n",
            "- **Sample Response**:\n",
            "```json\n",
            "{\n",
            "  \"success\": true,\n",
            "  \"transaction_id\": \"txn789\"\n",
            "}\n",
            "```\n",
            "\n",
            "## Additional Information\n",
            "\n",
            "### Base URL\n",
            "- **Production**: `https://api.sikkasoft.com/v2/payment`\n",
            "- **Sandbox**: `https://api.sikkasoft.com/v2/sandbox/payment`\n",
            "\n",
            "### PCI Compliance\n",
            "For applications handling credit card data:\n",
            "- Ensure compliance with PCI requirements.\n",
            "- The developer is responsible for maintaining PCI compliance on their front-end.\n",
            "\n",
            "### Testing Your Application\n",
            "You can use the sandbox environment for testing:\n",
            "1. Create a Sphere merchant account.\n",
            "2. Use the sandbox base URL for testing: `https://api.sikkasoft.com/v2/sandbox/payment`.\n",
            "\n",
            "### Additional Sample Data\n",
            "**Test Cards - Approved**\n",
            "| Card Type     | Card Number          | Exp Date | CVV |\n",
            "|---------------|----------------------|----------|-----|\n",
            "| Visa          | 4111111111111111     | 04/2029  | 123 |\n",
            "| MasterCard    | 5411111111111115     | 04/2029  | 777 |\n",
            "| American Express | 341111111111111  | 04/2029  | 4000 |\n",
            "\n",
            "**Test Cards - Declined**\n",
            "| Card Number       | Exp Date | Decline Type |\n",
            "|-------------------|----------|---------------|\n",
            "| 4012345678909     | 04/2029  | decline       |\n",
            "| 5555444433332226  | 04/2029  | call          |\n",
            "| 4444111144441111  | 04/2029  | carderror     |\n",
            "\n",
            "In conclusion, these endpoints empower your healthcare practice to create payment methods and process payments easily and securely. Always refer to the respective endpoint documentation for more details on parameters and request/response formats.\n",
            "\n",
            "# Frontend Code\n",
            "```javascript\n",
            "// src/components/CheckoutForm.js\n",
            "import React, { useState } from 'react';\n",
            "import axios from 'axios';\n",
            "\n",
            "const CheckoutForm = ({ requestKey, patientId }) => {\n",
            "  const [cardNumber, setCardNumber] = useState('');\n",
            "  const [expiration, setExpiration] = useState('');\n",
            "  const [cvc, setCvc] = useState('');\n",
            "  const [amount, setAmount] = useState(25); // Set your default amount\n",
            "  const [loading, setLoading] = useState(false);\n",
            "  const [error, setError] = useState(null);\n",
            "  const [success, setSuccess] = useState(false);\n",
            "  \n",
            "  const validateCardInfo = () => {\n",
            "    const cardNumberPattern = /^\\d{16}$/; // Basic validation for 16 digit card\n",
            "    const expirationPattern = /^(0[1-9]|1[0-2])\\/?([0-9]{2})$/; // MM/YY format\n",
            "    const cvcPattern = /^\\d{3}$/; // Basic validation for 3 digit CVC\n",
            "\n",
            "    return cardNumberPattern.test(cardNumber) && \n",
            "           expirationPattern.test(expiration) && \n",
            "           cvcPattern.test(cvc);\n",
            "  }\n",
            "\n",
            "  const handleSubmit = async (e) => {\n",
            "    e.preventDefault();\n",
            "    setLoading(true);\n",
            "    setError(null);\n",
            "    \n",
            "    if (!validateCardInfo()) {\n",
            "      setError(\"Invalid card information. Please check your entries.\");\n",
            "      setLoading(false);\n",
            "      return;\n",
            "    }\n",
            "    \n",
            "    try {\n",
            "      // Save payment method\n",
            "      const paymentMethodResponse = await axios.post(\n",
            "        'https://api.sikkasoft.com/v4/payment_methods',\n",
            "        {\n",
            "          patient_id: patientId,\n",
            "          card_data: {\n",
            "            number: cardNumber,\n",
            "            expiration: expiration,\n",
            "            cvc: cvc,\n",
            "          },\n",
            "        },\n",
            "        {\n",
            "          headers: {\n",
            "            Authorization: `Bearer ${requestKey}`,\n",
            "            'Content-Type': 'application/json',\n",
            "          },\n",
            "        }\n",
            "      );\n",
            "\n",
            "      if (paymentMethodResponse.data.success) {\n",
            "        const methodId = paymentMethodResponse.data.method_id;\n",
            "\n",
            "        // Process payment\n",
            "        const paymentResponse = await axios.post(\n",
            "          'https://api.sikkasoft.com/v4/payments',\n",
            "          {\n",
            "            method_id: methodId,\n",
            "            amount: amount,\n",
            "          },\n",
            "          {\n",
            "            headers: {\n",
            "              Authorization: `Bearer ${requestKey}`,\n",
            "              'Content-Type': 'application/json',\n",
            "            },\n",
            "          }\n",
            "        );\n",
            "\n",
            "        if (paymentResponse.data.success) {\n",
            "          setSuccess(true);\n",
            "        } else {\n",
            "          throw new Error('Payment processing failed');\n",
            "        }\n",
            "      } else {\n",
            "        throw new Error('Failed to save payment method');\n",
            "      }\n",
            "      \n",
            "    } catch (err) {\n",
            "      setError(err.message);\n",
            "    } finally {\n",
            "      setLoading(false);\n",
            "    }\n",
            "  };\n",
            "\n",
            "  if (success) {\n",
            "    return <PaymentSuccess />;\n",
            "  }\n",
            "\n",
            "  if (error) {\n",
            "    return <PaymentError message={error} />;\n",
            "  }\n",
            "\n",
            "  return (\n",
            "    <form onSubmit={handleSubmit}>\n",
            "      <h1>Checkout</h1>\n",
            "      <div>\n",
            "        <label>Card Number</label>\n",
            "        <input\n",
            "          type=\"text\"\n",
            "          value={cardNumber}\n",
            "          onChange={(e) => setCardNumber(e.target.value)}\n",
            "          required\n",
            "        />\n",
            "      </div>\n",
            "      <div>\n",
            "        <label>Expiration</label>\n",
            "        <input\n",
            "          type=\"text\"\n",
            "          value={expiration}\n",
            "          onChange={(e) => setExpiration(e.target.value)}\n",
            "          placeholder=\"MM/YY\"\n",
            "          required\n",
            "        />\n",
            "      </div>\n",
            "      <div>\n",
            "        <label>CVC</label>\n",
            "        <input\n",
            "          type=\"text\"\n",
            "          value={cvc}\n",
            "          onChange={(e) => setCvc(e.target.value)}\n",
            "          required\n",
            "        />\n",
            "      </div>\n",
            "      <div>\n",
            "        <label>Amount</label>\n",
            "        <input\n",
            "          type=\"number\"\n",
            "          value={amount}\n",
            "          readOnly\n",
            "        />\n",
            "      </div>\n",
            "      <button type=\"submit\" disabled={loading}>\n",
            "        {loading ? 'Processing...' : 'Pay Now'}\n",
            "      </button>\n",
            "      {loading && <p>Loading...</p>}\n",
            "    </form>\n",
            "  );\n",
            "};\n",
            "\n",
            "// src/components/PaymentSuccess.js\n",
            "import React from 'react';\n",
            "\n",
            "const PaymentSuccess = () => {\n",
            "  return (\n",
            "    <div>\n",
            "      <h1>Payment Successful!</h1>\n",
            "      <p>Your payment has been processed successfully. Thank you!</p>\n",
            "    </div>\n",
            "  );\n",
            "};\n",
            "\n",
            "// src/components/PaymentError.js\n",
            "import React from 'react';\n",
            "\n",
            "const PaymentError = ({ message }) => {\n",
            "  return (\n",
            "    <div>\n",
            "      <h1>Payment Error!</h1>\n",
            "      <p>{message}</p>\n",
            "    </div>\n",
            "  );\n",
            "};\n",
            "\n",
            "// Usage in a parent component or page\n",
            "const CheckoutPage = () => {\n",
            "  const requestKey = process.env.REACT_APP_REQUEST_KEY; // Store your request key in an environment variable\n",
            "  const patientId = /* secure method to get the patient ID */;\n",
            "\n",
            "  return (\n",
            "    <div>\n",
            "      <CheckoutForm requestKey={requestKey} patientId={patientId} />\n",
            "    </div>\n",
            "  );\n",
            "};\n",
            "\n",
            "export default CheckoutPage;\n",
            "```\n",
            "\n",
            "# Backend Code\n",
            "```javascript\n",
            "const express = require('express');\n",
            "const axios = require('axios');\n",
            "const bodyParser = require('body-parser');\n",
            "const { getRequestKey } = require('./secureKeyProvider'); // Secure method to retrieve request_key\n",
            "\n",
            "const app = express();\n",
            "app.use(bodyParser.json());\n",
            "\n",
            "// Middleware to obtain and refresh request_key\n",
            "const getRequestKeyMiddleware = async (req, res, next) => {\n",
            "    try {\n",
            "        req.request_key = await getRequestKey(); // Replace with actual key retrieval logic\n",
            "        next();\n",
            "    } catch (error) {\n",
            "        return res.status(500).json({ success: false, message: 'Failed to obtain request key.' });\n",
            "    }\n",
            "};\n",
            "\n",
            "// Save Payment Method Route\n",
            "app.post('/save_payment_method', getRequestKeyMiddleware, async (req, res) => {\n",
            "    const { patient_id, card_data } = req.body;\n",
            "\n",
            "    if (!patient_id || !card_data) {\n",
            "        return res.status(400).json({ success: false, message: 'patient_id and card_data are required.' });\n",
            "    }\n",
            "\n",
            "    try {\n",
            "        const response = await axios.post('https://api.sikkasoft.com/v4/payment_methods', {\n",
            "            patient_id,\n",
            "            card_data,\n",
            "        }, {\n",
            "            headers: {\n",
            "                Authorization: `Bearer ${req.request_key}`,\n",
            "                'Content-Type': 'application/json',\n",
            "            }\n",
            "        });\n",
            "\n",
            "        return res.status(201).json(response.data);\n",
            "    } catch (error) {\n",
            "        console.error('Error saving payment method:', error.message); // Mask sensitive data\n",
            "        return res.status(error.response?.status || 500).json({\n",
            "            success: false,\n",
            "            message: error.response ? 'Error saving payment method.' : 'Internal Server Error'\n",
            "        });\n",
            "    }\n",
            "});\n",
            "\n",
            "// Process Payment Route\n",
            "app.post('/process_payment', getRequestKeyMiddleware, async (req, res) => {\n",
            "    const { method_id, amount } = req.body;\n",
            "\n",
            "    if (!method_id || !amount) {\n",
            "        return res.status(400).json({ success: false, message: 'method_id and amount are required.' });\n",
            "    }\n",
            "\n",
            "    try {\n",
            "        const response = await axios.post('https://api.sikkasoft.com/v4/payments', {\n",
            "            method_id,\n",
            "            amount,\n",
            "        }, {\n",
            "            headers: {\n",
            "                Authorization: `Bearer ${req.request_key}`,\n",
            "                'Content-Type': 'application/json',\n",
            "            }\n",
            "        });\n",
            "\n",
            "        return res.status(200).json(response.data);\n",
            "    } catch (error) {\n",
            "        console.error('Error processing payment:', error.message); // Mask sensitive data\n",
            "        return res.status(error.response?.status || 500).json({\n",
            "            success: false,\n",
            "            message: error.response ? 'Error processing payment.' : 'Internal Server Error'\n",
            "        });\n",
            "    }\n",
            "});\n",
            "\n",
            "// Start the Express server\n",
            "const PORT = process.env.PORT || 3000;\n",
            "app.listen(PORT, () => {\n",
            "    console.log(`Server started on port ${PORT}`);\n",
            "});\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell implements a simple chat interface with memory and context retrieval:\n",
        "\n",
        "- **`conversation` list**  \n",
        "  - Keeps full history of user and assistant messages for follow‑up continuity.\n",
        "\n",
        "- **`chat_with_memory(question: str) -> str`**  \n",
        "  1. Appends the new user question to `conversation`.  \n",
        "  2. Retrieves relevant API docs passages from FAISS via `retrieve_api_context`.  \n",
        "  3. Constructs `system_messages` including:  \n",
        "     - Instructions to use only provided docs.  \n",
        "     - The full final Markdown doc (`doc`).  \n",
        "     - The FAISS‑retrieved passages.  \n",
        "  4. Combines `system_messages` with the entire `conversation` history.  \n",
        "  5. Sends the batch to the LLM (`gpt-4o-mini`) and obtains the assistant reply.  \n",
        "  6. Appends and returns the assistant’s answer.\n",
        "\n",
        "- **Example usage**  \n",
        "  - Runs three follow‑up questions, printing each answer.  \n",
        "  - Finally pretty‑prints the full `conversation` history.\n",
        "\n",
        "This enables iterative Q&A over the generated documentation and code, maintaining context across turns.\n"
      ],
      "metadata": {
        "id": "q6y82W5OALUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = []\n",
        "\n",
        "def chat_with_memory(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Ask a follow‑up question, using both the final Markdown doc and\n",
        "    vector‑retrieved context. Maintains full conversation history.\n",
        "    \"\"\"\n",
        "    # 1) Add the new user message to the history\n",
        "    conversation.append({\"role\": \"user\", \"content\": question})\n",
        "\n",
        "    # 2) Retrieve relevant chunks from your FAISS index\n",
        "    vector_ctx = retrieve_api_context(question)\n",
        "\n",
        "    # 3) Build the system + history messages\n",
        "    system_messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": (\n",
        "                \"You are an expert on Sikka API integrations. \"\n",
        "                \"Use ONLY the documentation and relevant passages provided to answer.\"\n",
        "            )\n",
        "        },\n",
        "        {\"role\": \"system\", \"content\": f\"Full Documentation:\\n\\n{doc}\"},\n",
        "        {\"role\": \"system\", \"content\": f\"Relevant Passages:\\n\\n{vector_ctx}\"}\n",
        "    ]\n",
        "\n",
        "    # 4) Combine all messages: system directives + prior conversation\n",
        "    messages = system_messages + conversation\n",
        "\n",
        "    # 5) Query the model\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages\n",
        "    )\n",
        "    answer = response.choices[0].message.content\n",
        "\n",
        "    # 6) Append the assistant’s answer to the history and return it\n",
        "    conversation.append({\"role\": \"assistant\", \"content\": answer})\n",
        "    return answer\n",
        "\n",
        "# Example usage:\n",
        "q1 = \"What headers do I need for the payment endpoint?\"\n",
        "print(\"A1:\", chat_with_memory(q1))\n",
        "\n",
        "q2 = \"And how do I refresh the request_key in my server code?\"\n",
        "print(\"A2:\", chat_with_memory(q2))\n",
        "\n",
        "q3 = \"How should the UI handle rate‑limit errors?\"\n",
        "print(\"A3:\", chat_with_memory(q3))\n",
        "\n",
        "# Finally, inspect the conversation history:\n",
        "import pprint\n",
        "print(\"\\n=== Conversation History ===\")\n",
        "pprint.pprint(conversation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIDp3DlVidme",
        "outputId": "79be37eb-5ec2-477b-c88f-3c32cdcc5872"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1: For the payment endpoint, you need the following headers:\n",
            "\n",
            "- **Authorization**: `Bearer <request_key>`\n",
            "- **Content-Type**: `application/json`\n",
            "A2: To refresh the `request_key` in your server code, you need to make a POST request to the `https://api.sikkasoft.com/v4/request_key` endpoint with the appropriate body and headers. Here is how you can do it:\n",
            "\n",
            "### Request\n",
            "**Endpoint:**  \n",
            "```\n",
            "POST https://api.sikkasoft.com/v4/request_key\n",
            "```\n",
            "\n",
            "**Headers:**\n",
            "```\n",
            "Content-Type: application/json\n",
            "```\n",
            "\n",
            "**Body:**\n",
            "```json\n",
            "{\n",
            "  \"grant_type\": \"refresh_key\",\n",
            "  \"app_id\": \"your_app_id\",\n",
            "  \"app_key\": \"your_app_key\"\n",
            "}\n",
            "```\n",
            "\n",
            "### Example Code Snippet\n",
            "You can implement it in your server code as follows:\n",
            "\n",
            "```javascript\n",
            "const axios = require('axios');\n",
            "\n",
            "const refreshRequestKey = async () => {\n",
            "  try {\n",
            "    const response = await axios.post('https://api.sikkasoft.com/v4/request_key', {\n",
            "      grant_type: 'refresh_key',\n",
            "      app_id: 'your_app_id', // Replace with your actual app_id\n",
            "      app_key: 'your_app_key', // Replace with your actual app_key\n",
            "    }, {\n",
            "      headers: {\n",
            "        'Content-Type': 'application/json',\n",
            "      },\n",
            "    });\n",
            "    \n",
            "    return response.data.request_key; // Return the new request_key\n",
            "  } catch (error) {\n",
            "    console.error('Error refreshing request key:', error.message);\n",
            "    throw new Error('Failed to refresh request key');\n",
            "  }\n",
            "};\n",
            "```\n",
            "\n",
            "Make sure to replace `'your_app_id'` and `'your_app_key'` with your actual application ID and key.\n",
            "A3: The UI should handle rate-limit errors (HTTP 429 status code) gracefully by implementing the following strategies:\n",
            "\n",
            "1. **Display User-Friendly Message**: Inform the user that they have hit a rate limit and that they should try again later. For example, you could show a message like:\n",
            "   ```plaintext\n",
            "   \"You have reached the limit for requests. Please try again in a few moments.\"\n",
            "   ```\n",
            "\n",
            "2. **Disable Actions**: Temporarily disable any actions that could lead to further API calls until the rate limit resets. This can prevent further frustration for the user.\n",
            "\n",
            "3. **Implement Automatic Retry**: If applicable, you can implement an automatic retry mechanism. Before retrying, ensure there is a delay defined by the X-Rate-Limit-Reset header from the response, which tells you when you can safely make another request.\n",
            "\n",
            "4. **Provide Feedback on Retry Countdown**: If you're implementing a retry timer, show a countdown or message indicating when the user can attempt the action again.\n",
            "\n",
            "5. **Logging and Monitoring**: Log rate-limit errors for monitoring purposes so that you can analyze patterns and understand when they occur most frequently, which can help in optimizing API calls.\n",
            "\n",
            "6. **Graceful Degradation**: If applicable, develop a fallback mechanism that allows users to continue using certain functionalities that don't require API calls, or show cached data if the situation permits.\n",
            "\n",
            "By taking these steps, you can enhance user experience even in scenarios where API usage is constrained due to rate limiting.\n",
            "\n",
            "=== Conversation History ===\n",
            "[{'content': 'What headers do I need for the payment endpoint?',\n",
            "  'role': 'user'},\n",
            " {'content': 'For the payment endpoint, you need the following headers:\\n'\n",
            "             '\\n'\n",
            "             '- **Authorization**: `Bearer <request_key>`\\n'\n",
            "             '- **Content-Type**: `application/json`',\n",
            "  'role': 'assistant'},\n",
            " {'content': 'And how do I refresh the request_key in my server code?',\n",
            "  'role': 'user'},\n",
            " {'content': 'To refresh the `request_key` in your server code, you need to '\n",
            "             'make a POST request to the '\n",
            "             '`https://api.sikkasoft.com/v4/request_key` endpoint with the '\n",
            "             'appropriate body and headers. Here is how you can do it:\\n'\n",
            "             '\\n'\n",
            "             '### Request\\n'\n",
            "             '**Endpoint:**  \\n'\n",
            "             '```\\n'\n",
            "             'POST https://api.sikkasoft.com/v4/request_key\\n'\n",
            "             '```\\n'\n",
            "             '\\n'\n",
            "             '**Headers:**\\n'\n",
            "             '```\\n'\n",
            "             'Content-Type: application/json\\n'\n",
            "             '```\\n'\n",
            "             '\\n'\n",
            "             '**Body:**\\n'\n",
            "             '```json\\n'\n",
            "             '{\\n'\n",
            "             '  \"grant_type\": \"refresh_key\",\\n'\n",
            "             '  \"app_id\": \"your_app_id\",\\n'\n",
            "             '  \"app_key\": \"your_app_key\"\\n'\n",
            "             '}\\n'\n",
            "             '```\\n'\n",
            "             '\\n'\n",
            "             '### Example Code Snippet\\n'\n",
            "             'You can implement it in your server code as follows:\\n'\n",
            "             '\\n'\n",
            "             '```javascript\\n'\n",
            "             \"const axios = require('axios');\\n\"\n",
            "             '\\n'\n",
            "             'const refreshRequestKey = async () => {\\n'\n",
            "             '  try {\\n'\n",
            "             '    const response = await '\n",
            "             \"axios.post('https://api.sikkasoft.com/v4/request_key', {\\n\"\n",
            "             \"      grant_type: 'refresh_key',\\n\"\n",
            "             \"      app_id: 'your_app_id', // Replace with your actual app_id\\n\"\n",
            "             \"      app_key: 'your_app_key', // Replace with your actual \"\n",
            "             'app_key\\n'\n",
            "             '    }, {\\n'\n",
            "             '      headers: {\\n'\n",
            "             \"        'Content-Type': 'application/json',\\n\"\n",
            "             '      },\\n'\n",
            "             '    });\\n'\n",
            "             '    \\n'\n",
            "             '    return response.data.request_key; // Return the new '\n",
            "             'request_key\\n'\n",
            "             '  } catch (error) {\\n'\n",
            "             \"    console.error('Error refreshing request key:', \"\n",
            "             'error.message);\\n'\n",
            "             \"    throw new Error('Failed to refresh request key');\\n\"\n",
            "             '  }\\n'\n",
            "             '};\\n'\n",
            "             '```\\n'\n",
            "             '\\n'\n",
            "             \"Make sure to replace `'your_app_id'` and `'your_app_key'` with \"\n",
            "             'your actual application ID and key.',\n",
            "  'role': 'assistant'},\n",
            " {'content': 'How should the UI handle rate‑limit errors?', 'role': 'user'},\n",
            " {'content': 'The UI should handle rate-limit errors (HTTP 429 status code) '\n",
            "             'gracefully by implementing the following strategies:\\n'\n",
            "             '\\n'\n",
            "             '1. **Display User-Friendly Message**: Inform the user that they '\n",
            "             'have hit a rate limit and that they should try again later. For '\n",
            "             'example, you could show a message like:\\n'\n",
            "             '   ```plaintext\\n'\n",
            "             '   \"You have reached the limit for requests. Please try again in '\n",
            "             'a few moments.\"\\n'\n",
            "             '   ```\\n'\n",
            "             '\\n'\n",
            "             '2. **Disable Actions**: Temporarily disable any actions that '\n",
            "             'could lead to further API calls until the rate limit resets. '\n",
            "             'This can prevent further frustration for the user.\\n'\n",
            "             '\\n'\n",
            "             '3. **Implement Automatic Retry**: If applicable, you can '\n",
            "             'implement an automatic retry mechanism. Before retrying, ensure '\n",
            "             'there is a delay defined by the X-Rate-Limit-Reset header from '\n",
            "             'the response, which tells you when you can safely make another '\n",
            "             'request.\\n'\n",
            "             '\\n'\n",
            "             \"4. **Provide Feedback on Retry Countdown**: If you're \"\n",
            "             'implementing a retry timer, show a countdown or message '\n",
            "             'indicating when the user can attempt the action again.\\n'\n",
            "             '\\n'\n",
            "             '5. **Logging and Monitoring**: Log rate-limit errors for '\n",
            "             'monitoring purposes so that you can analyze patterns and '\n",
            "             'understand when they occur most frequently, which can help in '\n",
            "             'optimizing API calls.\\n'\n",
            "             '\\n'\n",
            "             '6. **Graceful Degradation**: If applicable, develop a fallback '\n",
            "             'mechanism that allows users to continue using certain '\n",
            "             \"functionalities that don't require API calls, or show cached \"\n",
            "             'data if the situation permits.\\n'\n",
            "             '\\n'\n",
            "             'By taking these steps, you can enhance user experience even in '\n",
            "             'scenarios where API usage is constrained due to rate limiting.',\n",
            "  'role': 'assistant'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next Steps\n",
        "\n",
        "- **Extract core pipeline functions**  \n",
        "  Consolidate `run_optimizer`, `run_api_docs_step`, `run_frontend_step`, `run_backend_step`, `run_formatter_step`, and `chat_with_memory` into a standalone module (e.g. `ai_pipeline.py`).\n",
        "\n",
        "- **Build a backend endpoint**  \n",
        "  Create an Express route that accepts user messages, invokes the AI pipeline functions, and returns JSON or Markdown responses.\n",
        "\n",
        "- **Develop a React chatbot UI**  \n",
        "  Scaffold a simple React app with a chat interface that sends user input to your backend and displays streaming or batched AI responses.\n",
        "\n",
        "- **Centralize configuration & secrets**  \n",
        "  Move API keys, model names, and other settings into a `.env` (or equivalent) and load via `dotenv` or environment variables.\n",
        "\n",
        "- **Add testing**  \n",
        "  Write unit tests that mock the AI calls, plus integration tests that spin up your backend and verify end‑to‑end behavior.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5B6HUJ2cmEYw"
      }
    }
  ]
}