{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyPXiYbBH0uGiXkZdj2oOaQk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SomeiLam/api-docs-ai-agent-colab/blob/main/sikka_apis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Summary\n",
        "\n",
        "This Colab notebook implements a full‑stack, retrieval‑augmented code generation pipeline for building payment integration apps using Sikka APIs. It breaks the user’s high‑level request into discrete AI agents that each handle one piece of the workflow:\n",
        "\n",
        "1. **Query Optimizer**  \n",
        "   Normalizes and scopes the user’s message, detects tech stacks, and produces structured prompts.  \n",
        "2. **API‑Docs Generator**  \n",
        "   Retrieves relevant API reference snippets via FAISS and generates detailed endpoint documentation (base URL, version, headers, parameters, sample requests/responses).  \n",
        "3. **Frontend Code Generator**  \n",
        "   Produces React (or Next.js) components for the checkout UI, wiring up form state, loading, and error handling.  \n",
        "4. **Backend Code Generator**  \n",
        "   Generates Node.js + Express routes that obtain/refresh the Sikka `request_key`, save cards, and process payments.  \n",
        "5. **Code Evaluator & Refinement**  \n",
        "   Splits evaluation into frontend/backend reviewers, collects issues and suggestions, and applies fixes via a reusable refinement agent.  \n",
        "6. **Documentation Formatter**  \n",
        "   Assembles the optimized query, tech stack, API docs, frontend code, and backend code into a polished Markdown deliverable.  \n",
        "7. **Follow‑up QA**  \n",
        "   Maintains conversational memory and combines the final document with FAISS‑retrieved context to answer user follow‑up questions without re‑running the full pipeline.\n",
        "\n",
        "Together, these agents demonstrate how to orchestrate multiple LLM calls in Colab—leveraging CrewAI, FAISS, and OpenAI’s GPT models—to automate everything from requirements analysis to production‑ready code and documentation.\n",
        "\n",
        "---\n",
        "\n",
        "### Notebook Installation\n",
        "\n",
        "Before running any cells, install and pin your dependencies for a reproducible environment. In a new Colab cell, run\n",
        "```\n",
        "# Install core libraries for FAISS vector search, OpenAI API access, tokenization, agent orchestration, and retrieval workflows\n",
        "!pip install --upgrade --no-cache-dir \\\n",
        "    faiss-cpu    # vector similarity search engine for nearest‑neighbor lookup  \n",
        "    openai       # official OpenAI Python client for embeddings and chat completions  \n",
        "    tiktoken     # high‑speed tokenizer compatible with OpenAI models  \n",
        "    langchain    # framework for building retrieval‑augmented LLM applications  \n",
        "    crewai       # library for coordinating multi‑agent AI workflows  \n",
        "```"
      ],
      "metadata": {
        "id": "7OohWzNbognk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u3OYvvALXrY",
        "outputId": "5e217556-15a4-4896-d57b-b35a9d5646cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.7.3)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Collecting openai\n",
            "  Downloading openai-1.75.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.4.0)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.0.335)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: crewai in /usr/local/lib/python3.11/dist-packages (0.1.0)\n",
            "Collecting crewai\n",
            "  Downloading crewai-0.114.0-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.3.32-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.4.4)\n",
            "Requirement already satisfied: auth0-python>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from crewai) (4.9.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.9.0)\n",
            "Requirement already satisfied: chromadb>=0.5.23 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.0.5)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from crewai) (8.1.8)\n",
            "Requirement already satisfied: instructor>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.7.9)\n",
            "Requirement already satisfied: json-repair>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.41.1)\n",
            "Requirement already satisfied: json5>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.12.0)\n",
            "Requirement already satisfied: jsonref>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.1.0)\n",
            "Requirement already satisfied: litellm==1.60.2 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.60.2)\n",
            "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from crewai) (3.1.5)\n",
            "Requirement already satisfied: opentelemetry-api>=1.30.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.30.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.30.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.32.1)\n",
            "Requirement already satisfied: pdfplumber>=0.11.4 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.11.6)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.0.0)\n",
            "Requirement already satisfied: pyvis>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.3.2)\n",
            "Requirement already satisfied: tomli-w>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.2.0)\n",
            "Requirement already satisfied: tomli>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from crewai) (2.2.1)\n",
            "Requirement already satisfied: uv>=0.4.25 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.6.14)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (3.11.15)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (8.6.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (4.23.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (0.21.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: cryptography>=43.0.1 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (43.0.3)\n",
            "Requirement already satisfied: pyjwt>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (2.10.1)\n",
            "Requirement already satisfied: urllib3>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (2.3.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.7.6)\n",
            "Requirement already satisfied: fastapi==0.115.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.115.9)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (0.34.1)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (3.25.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.21.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.53b1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (8.5.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (3.10.16)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (13.9.4)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.9->chromadb>=0.5.23->crewai) (0.45.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (0.16)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (2.33.1)\n",
            "Collecting tenacity>=8.2.3 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.5->crewai) (2.0.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.30.0->crewai) (1.2.18)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (1.32.1)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-proto==1.32.1->opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (5.29.4)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.30.0->crewai) (0.53b1)\n",
            "Requirement already satisfied: pdfminer.six==20250327 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai) (20250327)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber>=0.11.4->crewai) (3.4.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (4.0.5)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (3.4.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (1.19.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.5.23->crewai) (1.2.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=43.0.1->auth0-python>=4.7.1->crewai) (1.17.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.30.0->crewai) (1.17.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm==1.60.2->crewai) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.60.2->crewai) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (3.2.2)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (1.13.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai) (0.53b1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.23->crewai) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.23->crewai) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.23->crewai) (3.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm==1.60.2->crewai) (0.30.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.5.23->crewai) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (1.0.5)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (15.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=43.0.1->auth0-python>=4.7.1->crewai) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.60.2->crewai) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.60.2->crewai) (2025.3.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.23->crewai) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (0.6.1)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m157.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.75.0-py3-none-any.whl (646 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m207.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m143.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m206.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crewai-0.114.0-py3-none-any.whl (285 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.5/285.5 kB\u001b[0m \u001b[31m188.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.3.32-py3-none-any.whl (358 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.2/358.2 kB\u001b[0m \u001b[31m209.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: tenacity, faiss-cpu, tiktoken, openai, langsmith, langchain, crewai\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 8.5.0\n",
            "    Uninstalling tenacity-8.5.0:\n",
            "      Successfully uninstalled tenacity-8.5.0\n",
            "  Attempting uninstall: faiss-cpu\n",
            "    Found existing installation: faiss-cpu 1.7.3\n",
            "    Uninstalling faiss-cpu-1.7.3:\n",
            "      Successfully uninstalled faiss-cpu-1.7.3\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.4.0\n",
            "    Uninstalling tiktoken-0.4.0:\n",
            "      Successfully uninstalled tiktoken-0.4.0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 0.28.1\n",
            "    Uninstalling openai-0.28.1:\n",
            "      Successfully uninstalled openai-0.28.1\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.0.92\n",
            "    Uninstalling langsmith-0.0.92:\n",
            "      Successfully uninstalled langsmith-0.0.92\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.0.335\n",
            "    Uninstalling langchain-0.0.335:\n",
            "      Successfully uninstalled langchain-0.0.335\n",
            "  Attempting uninstall: crewai\n",
            "    Found existing installation: crewai 0.1.0\n",
            "    Uninstalling crewai-0.1.0:\n",
            "      Successfully uninstalled crewai-0.1.0\n",
            "Successfully installed crewai-0.114.0 faiss-cpu-1.10.0 langchain-0.3.23 langsmith-0.3.32 openai-1.75.0 tenacity-9.1.2 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --no-cache-dir faiss-cpu openai tiktoken langchain crewai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This initialization cell prepares our Colab environment by:\n",
        "\n",
        "- **Importing standard libraries**  \n",
        "  - `os`, `pathlib` for file and environment management  \n",
        "  - `json`, `pickle` for data serialization  \n",
        "  - `textwrap` for text formatting  \n",
        "  - `getpass` for optional secure input  \n",
        "  - `typing` helpers (`List`, `Dict`) for clearer function signatures  \n",
        "\n",
        "- **Importing core third‑party packages**  \n",
        "  - `numpy` for numerical arrays  \n",
        "  - `faiss` for fast similarity search over embeddings  \n",
        "  - `tiktoken` for tokenizing inputs to OpenAI models  \n",
        "  - `openai` for interacting with OpenAI’s embeddings and chat APIs  \n",
        "\n",
        "- **Loading your OpenAI API key securely**  \n",
        "  - Go to the Colab toolbar, click the **lock icon (Secrets pane)** on the left, choose **“Add secret”**, enter **`OPENAI_API_KEY`** as the name and paste your key as the value.  \n",
        "  - This makes it available via `from google.colab import userdata` and `userdata.get(\"OPENAI_API_KEY\")`.  \n",
        "\n",
        "- **Setting the embedding model**  \n",
        "  - `EMBED_MODEL = \"text-embedding-3-small\"` will be used for all vectorization calls.  \n",
        "\n",
        "With these steps, the notebook can safely call the OpenAI and FAISS-based vector search functions without exposing your secret in plain code.\n"
      ],
      "metadata": {
        "id": "SgK9kXoBuhsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pathlib\n",
        "import textwrap\n",
        "import pickle\n",
        "import getpass\n",
        "from typing import List, Dict\n",
        "\n",
        "import numpy as np\n",
        "import faiss\n",
        "import tiktoken\n",
        "import openai\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load the OpenAI API key from Colab secrets and set it as an environment variable\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "# Name of the embedding model to use for vectorization\n",
        "EMBED_MODEL = \"text-embedding-3-small\"\n"
      ],
      "metadata": {
        "id": "_I9m4P5vLc6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines and runs a **`collect_docs`** function to extract structured documentation from the Postman collection JSON:\n",
        "\n",
        "1. **Loading & Parsing**  \n",
        "   - Reads `sikka-apis.json` into `root`.\n",
        "\n",
        "2. **Depth‑First Traversal**  \n",
        "   - Uses a stack to walk through nested dicts and lists.\n",
        "   - Tracks the “path” (e.g. `Sikka API v4 › Authorization › Generate request_key`) to locate each item.\n",
        "\n",
        "3. **Extracting Snippets**  \n",
        "   - Gathers:\n",
        "     - Plain-text `description` fields.\n",
        "     - Request-level docs & raw JSON bodies.\n",
        "     - Sample responses (`response.body`).\n",
        "     - Inline scripts (`event → script.exec`).\n",
        "\n",
        "4. **Output Format**  \n",
        "   - Returns a list of dicts, each with:\n",
        "     - `\"content\"`: a markdown string combining the snippets.\n",
        "     - `\"path\"`: the hierarchical breadcrumb.\n",
        "\n",
        "5. **Role in Pipeline**  \n",
        "   - These extracted docs become the **knowledge base** for FAISS indexing and subsequent retrieval‑augmented LLM prompts.\n"
      ],
      "metadata": {
        "id": "vS7BYu4pvRy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and parse the Postman collection JSON file\n",
        "FILE = pathlib.Path(\"sikka-apis.json\")   # Path to the raw API spec\n",
        "root = json.loads(FILE.read_text())      # Parse JSON into Python object\n",
        "\n",
        "def collect_docs(node):\n",
        "    \"\"\"\n",
        "    Traverse a Postman collection (dicts & lists) depth‑first, extracting:\n",
        "      - Resource & request descriptions\n",
        "      - Endpoint (METHOD + full URL)\n",
        "      - Headers\n",
        "      - Request body\n",
        "      - Response samples\n",
        "      - Example scripts\n",
        "\n",
        "    Returns a list of {\"content\": markdown, \"path\": hierarchical name}.\n",
        "    \"\"\"\n",
        "    stack, out = [([], node)], []\n",
        "\n",
        "    while stack:\n",
        "        path, cur = stack.pop()\n",
        "\n",
        "        if isinstance(cur, dict):\n",
        "            name     = cur.get(\"name\") or \"<no‑name>\"\n",
        "            new_path = path + [name]\n",
        "            buckets  = []\n",
        "\n",
        "            # 1) Resource‑level description\n",
        "            if desc := cur.get(\"description\"):\n",
        "                buckets.append(\"**Description:**\\n\" + desc.strip())\n",
        "\n",
        "            # 2) Request block\n",
        "            req    = cur.get(\"request\", {}) or {}\n",
        "            method = req.get(\"method\", \"\").upper()\n",
        "\n",
        "            # Build the full URL (either raw or protocol + host + path)\n",
        "            raw_url = req.get(\"url\", {}).get(\"raw\")\n",
        "            if not raw_url and isinstance(req.get(\"url\"), dict):\n",
        "                u = req[\"url\"]\n",
        "                host = \".\".join(u.get(\"host\", []))\n",
        "                path = \"/\".join(u.get(\"path\", []))\n",
        "                raw_url = f\"{u.get('protocol','https')}://{host}/{path}\"\n",
        "\n",
        "            # 2a) Request‑level description\n",
        "            if rdesc := req.get(\"description\"):\n",
        "                buckets.append(\"**Request Description:**\\n\" + rdesc.strip())\n",
        "\n",
        "            # 2b) Endpoint line\n",
        "            if method and raw_url:\n",
        "                buckets.append(f\"**Endpoint:** `{method} {raw_url}`\")\n",
        "\n",
        "            # 2c) Headers\n",
        "            if hdrs := req.get(\"header\"):\n",
        "                lines = [\n",
        "                    f\"- `{h.get('key')}`: `{h.get('value')}`\"\n",
        "                    for h in hdrs\n",
        "                ]\n",
        "                buckets.append(\"**Headers:**\\n\" + \"\\n\".join(lines))\n",
        "\n",
        "            # 2d) Request body\n",
        "            if raw_body := req.get(\"body\", {}).get(\"raw\"):\n",
        "                buckets.append(\n",
        "                    \"**Request Body:**\\n```json\\n\"\n",
        "                    + raw_body[:2000]\n",
        "                    + \"\\n```\"\n",
        "                )\n",
        "\n",
        "            # 3) Response samples\n",
        "            for resp in cur.get(\"response\", []):\n",
        "                status = resp.get(\"code\") or resp.get(\"status\", \"\")\n",
        "                if body := resp.get(\"body\"):\n",
        "                    label = f\"**Response ({status})**\" if status else \"**Response**\"\n",
        "                    buckets.append(\n",
        "                        f\"{label}:\\n```json\\n\"\n",
        "                        + body[:2000]\n",
        "                        + \"\\n```\"\n",
        "                    )\n",
        "\n",
        "            # 4) Event scripts (tests/examples)\n",
        "            for ev in cur.get(\"event\", []):\n",
        "                exec_lines = ev.get(\"script\", {}).get(\"exec\") or []\n",
        "                if exec_lines:\n",
        "                    buckets.append(\n",
        "                        \"**Example Script:**\\n```javascript\\n\"\n",
        "                        + \"\\n\".join(exec_lines)[:2000]\n",
        "                        + \"\\n```\"\n",
        "                    )\n",
        "\n",
        "            # If we have any extracted pieces, save them\n",
        "            if buckets:\n",
        "                out.append({\n",
        "                    \"content\": (\n",
        "                        f\"# {' › '.join(new_path)}\\n\\n\"\n",
        "                        + \"\\n\\n\".join(buckets)\n",
        "                    ),\n",
        "                    \"path\": \" › \".join(new_path)\n",
        "                })\n",
        "\n",
        "            # Recurse into child items\n",
        "            for child in cur.get(\"item\", []):\n",
        "                stack.append((new_path, child))\n",
        "\n",
        "        elif isinstance(cur, list):\n",
        "            for itm in cur:\n",
        "                stack.append((path, itm))\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "# Run the collector and show a quick summary\n",
        "docs = collect_docs(root)\n",
        "print(\"Total docs captured:\", len(docs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atx7CSq4LeXi",
        "outputId": "d34b4b5d-c466-46a2-82ea-9d3dfb554ca8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total docs captured: 392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell configures and demonstrates how to split raw documentation entries into manageable chunks for embedding and retrieval:\n",
        "\n",
        "- **Importing text splitters**  \n",
        "  - `RecursiveCharacterTextSplitter` (general‑purpose, prioritizes paragraphs and lines)  \n",
        "  - `MarkdownTextSplitter` (optional, preserves markdown headings and fenced code)  \n",
        "\n",
        "- **Configuring the splitter**  \n",
        "  - `chunk_size=3000` characters target  \n",
        "  - `chunk_overlap=150` characters overlap to boost retrieval recall  \n",
        "  - `separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]` to split on paragraphs, then lines, then words  \n",
        "\n",
        "- **Defining `smart_chunk_docs(docs)`**  \n",
        "  - Iterates over each doc entry  \n",
        "  - Uses the splitter to break `content` into `pieces`  \n",
        "  - Attaches metadata `{ \"path\": ..., \"chunk\": index }` to each piece  \n",
        "\n",
        "- **Demonstration**  \n",
        "  - `docs_raw = collect_docs(root)` gathers ~392 full entries  \n",
        "  - `docs_chunk = smart_chunk_docs(docs_raw)` produces ~517 chunks  \n",
        "  - Prints before/after counts and an example metadata dict  \n",
        "\n",
        "- **Role in Pipeline**  \n",
        "  Splitting ensures each chunk is small enough (<3000 chars) for embedding models while maintaining context, improving FAISS similarity search for downstream prompt construction.  \n"
      ],
      "metadata": {
        "id": "qzp8Tn80wl1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownTextSplitter\n",
        "\n",
        "# NOTE: We’re not using smart_chunk_docs here because our collected docs\n",
        "# are already well‑structured and sized appropriately for embedding.\n",
        "# In general, for unstructured text, you could split into ~3k‑char chunks:\n",
        "# splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=150, separators=[\"\\n\\n\",\"\\n\",\" \",\"\"])\n",
        "# or use MarkdownTextSplitter to preserve headings/code fences.\n",
        "#\n",
        "# But for our Postman‑derived docs, each entry is its own “chunk” and passed\n",
        "# directly to the embedder.\n",
        "\n",
        "def smart_chunk_docs(docs):\n",
        "    \"\"\"\n",
        "    (Optional) Split large docs into overlapping sub‑chunks for retrieval.\n",
        "    Not used in this pipeline since each doc entry is already appropriately sized.\n",
        "    \"\"\"\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=3000,\n",
        "        chunk_overlap=150,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "    )\n",
        "    out = []\n",
        "    for d in docs:\n",
        "        pieces = splitter.split_text(d[\"content\"])\n",
        "        meta   = d.get(\"meta\") or {\"path\": d.get(\"path\", \"\")}\n",
        "        for i, part in enumerate(pieces):\n",
        "            out.append({\"content\": part, \"meta\": {**meta, \"chunk\": i}})\n",
        "    return out\n",
        "\n",
        "# Use the raw docs directly for embedding/retrieval:\n",
        "docs_raw = collect_docs(root)         # e.g. 392 entries\n",
        "print(\"Docs to index:\", len(docs_raw))\n",
        "docs_chunk = smart_chunk_docs(docs_raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWGnlDYsLg3L",
        "outputId": "81fd8d5d-790f-4af8-fd66-f8f1c5181375"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Docs to index: 392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell builds our FAISS vector index by embedding each documentation chunk:\n",
        "\n",
        "- **Client setup**  \n",
        "  - Uses the `OpenAI` client with your `api_key` for embedding calls.  \n",
        "\n",
        "- **Defining `embed_texts`**  \n",
        "  - Wrapper around the new OpenAI ≥1.0.0 SDK  \n",
        "  - Takes a list of strings plus an embedding model name  \n",
        "  - Returns a list of float vectors in the same order as inputs  \n",
        "\n",
        "- **Batch embedding loop**  \n",
        "  - Splits `docs_raw` into batches of size 96  \n",
        "  - Calls `embed_texts` for each batch to avoid rate or size limits  \n",
        "  - Accumulates all embeddings into `vecs`  \n",
        "\n",
        "- **FAISS index creation**  \n",
        "  - Converts `vecs` to a NumPy array of type `float32`  \n",
        "  - Initializes an inner‑product index (`IndexFlatIP`) matching the embedding dimension  \n",
        "  - Adds all vectors to the index for fast similarity search  \n",
        "\n",
        "- **Verification**  \n",
        "  - Prints the total number of vectors indexed (`index.ntotal`)  \n",
        "\n",
        "This prepares the FAISS index for nearest‑neighbor retrieval in downstream prompt construction.\n"
      ],
      "metadata": {
        "id": "jnnHZB_vxNDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "def embed_texts(texts: list[str], model: str = EMBED_MODEL) -> list[list[float]]:\n",
        "    \"\"\"\n",
        "    Returns embeddings for a list of texts using the OpenAI SDK client.\n",
        "    \"\"\"\n",
        "    resp = client.embeddings.create(model=model, input=texts)\n",
        "    return [e.embedding for e in resp.data]\n",
        "\n",
        "# Batch‑embed all raw document chunks and build a FAISS index\n",
        "vecs, BATCH = [], 96\n",
        "for i in range(0, len(docs_raw), BATCH):\n",
        "    batch = [d[\"content\"] for d in docs_raw[i:i+BATCH]]\n",
        "    vecs.extend(embed_texts(batch))\n",
        "\n",
        "# Convert to NumPy float32 array and index with inner‑product similarity\n",
        "vecs = np.asarray(vecs, dtype=\"float32\")\n",
        "index = faiss.IndexFlatIP(vecs.shape[1])\n",
        "index.add(vecs)\n",
        "\n",
        "print(\"FAISS index size:\", index.ntotal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fku7VWSLiDc",
        "outputId": "327d09a9-5ee1-40a0-a259-4248f65b3d0b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index size: 392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**  \n",
        "\n",
        "This helper function lets you query the raw Sikka API documentation “knowledge base” without triggering the full pipeline. It:\n",
        "\n",
        "- **Embeds the user query**  \n",
        "  - Calls `embed_texts` to get the query vector  \n",
        "- **Performs a FAISS lookup**  \n",
        "  - Retrieves the top `k` most similar document chunks  \n",
        "- **Builds a minimal LLM prompt**  \n",
        "  - System instruction: “Answer only from context; say ‘Not found’ otherwise.”  \n",
        "  - User message: includes the retrieved context and the original question  \n",
        "- **Invokes the chat model**  \n",
        "  - Uses `gpt-4o-mini` and returns the assistant’s text response  \n",
        "\n",
        "You can call `ask_sikka(\"your question\")` to test how well the vector store + LLM answers direct questions from the docs.\n"
      ],
      "metadata": {
        "id": "TZpM5eZFx_Nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_sikka(\n",
        "    query: str,\n",
        "    k: int = 4,\n",
        "    model: str = \"gpt-4o-mini\",\n",
        "    debug: bool = False\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Retrieve the top‑k relevant chunks for `query` from your FAISS index,\n",
        "    then ask the chat model to answer using ONLY that context.\n",
        "\n",
        "    Args:\n",
        "      query: The user’s question.\n",
        "      k: Number of chunks to retrieve.\n",
        "      model: Which chat model to use.\n",
        "      debug: If True, print each retrieved chunk with its score.\n",
        "\n",
        "    Returns:\n",
        "      The assistant’s reply (stripped of whitespace).\n",
        "    \"\"\"\n",
        "    # 1) Embed the query\n",
        "    embedding: List[float] = embed_texts([query])[0]\n",
        "\n",
        "    # 2) FAISS search for top-k similar docs\n",
        "    distances, indices = index.search(\n",
        "        np.array([embedding], dtype=\"float32\"),\n",
        "        k\n",
        "    )\n",
        "\n",
        "    # 3) Debug output of retrieved snippets\n",
        "    if debug:\n",
        "        for dist, idx in zip(distances[0], indices[0]):\n",
        "            snippet = docs_chunk[idx][\"content\"]\n",
        "            print(f\"[DEBUG] Chunk {idx} (score {dist:.3f}):\\n{snippet}\\n\")\n",
        "\n",
        "    # 4) Build the context string\n",
        "    context = \"\\n\\n---\\n\\n\".join(\n",
        "        docs_chunk[i][\"content\"] for i in indices[0]\n",
        "    )\n",
        "\n",
        "    # 5) Ask the model with a strict “only-from-context” instruction\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"Answer **only** from the context below; if it's not in the context, reply 'Not found'.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Context:\\n{context}\\n\\nQuestion: {query}\"\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 6) Return the assistant’s reply\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "\n",
        "# ── Example Usage ─────────────────────────────────────────────────────\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    for q in [\n",
        "        \"For the POST /v2/payment/store-card endpoint, list its headers and parameters.\",\n",
        "        \"What is the endpoint for save a card?\"\n",
        "    ]:\n",
        "        print(f\"Q: {q}\")\n",
        "        print(\"A:\", ask_sikka(q))\n",
        "        # print(\"A:\", ask_sikka(q, debug=True))\n",
        "        print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "90WpqVXALj7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09244795-3c69-4369-8a3b-a1bc4360970f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: For the POST /v2/payment/store-card endpoint, list its headers and parameters.\n",
            "A: **Headers:**\n",
            "- `Content-Type`: `application/json`\n",
            "\n",
            "**Parameters:**\n",
            "```json\n",
            "{\n",
            "    \"request_key\": \"request_key - mandatory\",\n",
            "    \"patient_id\": \"patient_id - mandatory\",\n",
            "    \"guarantor_id\": \"guarantor_id - mandatory\",\n",
            "    \"practice_id\": \"practice_id - mandatory\",\n",
            "    \"cust_id\": \"cust_id - mandatory\",\n",
            "    \"provider_id\": \"provider_id - optional\",\n",
            "    \"name\": \"name - mandatory\",\n",
            "    \"zipcode\": \"zipcode - mandatory\",\n",
            "    \"billing_id\": \"billing_id - mandatory\",\n",
            "    \"is_update_default\": \"true- mandatory\",\n",
            "    \"is_default\": \"true/false\"\n",
            "}\n",
            "```\n",
            "----------------------------------------\n",
            "Q: What is the endpoint for save a card?\n",
            "A: The endpoint for saving a card is `POST https://api.sikkasoft.com/v2/payment/store_card`.\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines the `OPTIMIZER_TEMPLATE` string, which primes the Query Optimizer Agent to:\n",
        "\n",
        "- **Validate Scope**  \n",
        "  - Checks if the user’s request pertains to building or integrating with Sikka APIs.  \n",
        "  - If out‑of‑scope, instructs the agent to output a minimal JSON and stop.\n",
        "\n",
        "- **Detect Tech Stack**  \n",
        "  - Parses the user message for frontend frameworks/languages (e.g. React, Next.js, TypeScript).  \n",
        "  - Parses for backend frameworks/languages (e.g. Node.js, Express, Python, Flask).  \n",
        "  - Falls back to “React + JavaScript” front end and “Node.js + Express + JavaScript” back end if none are detected.\n",
        "\n",
        "- **Rewrite & Decompose**  \n",
        "  - Produces a one‑sentence `optimized_query` restating the user’s goal.  \n",
        "  - Generates **four** specialized prompts under `prompts` for downstream agents:\n",
        "    1. **api_docs** – Instructs how to identify and document all required Sikka endpoints, including full base URLs, auth flow, headers, parameters, and examples.  \n",
        "    2. **frontend** – Guides the UI agent to build the frontend with the detected framework, integrate the endpoints, and handle state/loading/errors.  \n",
        "    3. **backend** – Directs the backend agent to implement routes in the detected framework, handle `request_key` acquisition/refresh, and call the endpoints returning JSON.  \n",
        "    4. **formatter** – Tells the formatter agent to assemble everything into a single Markdown document with specified headings.\n",
        "\n",
        "- **Define JSON Output Schema**  \n",
        "  - Specifies the exact structure the optimizer must return, containing:  \n",
        "    ```json\n",
        "    {\n",
        "      \"scope_ok\": true|false,\n",
        "      \"optimized_query\": \"...\",\n",
        "      \"tech_stack\": {\"frontend\": \"...\", \"backend\": \"...\"},\n",
        "      \"prompts\": {\n",
        "        \"api_docs\": \"...\",\n",
        "        \"frontend\": \"...\",\n",
        "        \"backend\": \"...\",\n",
        "        \"formatter\": \"...\"\n",
        "      }\n",
        "    }\n",
        "    ```  \n",
        "  - Emphasizes “no extra keys” to ensure downstream agents receive a strictly consistent payload.\n"
      ],
      "metadata": {
        "id": "5wjUY7o48mhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt template  ─────────────────────────────────────────────\n",
        "\n",
        "OPTIMIZER_TEMPLATE = \"\"\"\n",
        "You are the Query Optimizer for a multi‑agent system that builds full‑stack apps with Sikka APIs.\n",
        "\n",
        "USER_MESSAGE:\n",
        "\\\"\\\"\\\"{user_message}\\\"\\\"\\\"\n",
        "\n",
        "Step 1: Scope\n",
        "• If the message is not about building or integrating Sikka APIs, output exactly:\n",
        "  {{ \"scope_ok\": false, \"reason\": \"short explanation\" }}\n",
        "  and STOP.\n",
        "\n",
        "Step 2: Tech stack\n",
        "• Detect any frontend frameworks/languages (e.g. React, Next.js, TypeScript).\n",
        "• Detect any backend frameworks/languages (e.g. Node.js, Express, Python, Flask).\n",
        "• If none are found, default to “React + JavaScript” front end and “Node.js + Express + JavaScript” back end.\n",
        "\n",
        "Step 3: Rewrite & decompose\n",
        "• Produce one sentence `optimized_query` restating the goal.\n",
        "• Produce **four** prompts under `prompts` with these keys:\n",
        "\n",
        "  1. **api_docs**\n",
        "     – Identify all required Sikka endpoints for `optimized_query`.\n",
        "     – For each endpoint, specify the **full base URL including version** (e.g. `https://api.sikkasoft.com/v4`), the path, and HTTP method.\n",
        "     – Document the authentication flow (request_key lifecycle).\n",
        "     – List required headers and body/query parameters per endpoint.\n",
        "     – Include a sample request and a sample response for each endpoint.\n",
        "\n",
        "  2. **frontend**\n",
        "     – Build the UI using the detected frontend framework.\n",
        "     – Call the endpoints identified in `api_docs`.\n",
        "     – Specify component/file names.\n",
        "     – Handle form state, loading indicators, and error displays.\n",
        "\n",
        "  3. **backend**\n",
        "     – Implement server routes using the detected backend framework.\n",
        "     – Include code to obtain and refresh the request_key.\n",
        "     – Show how to call each Sikka endpoint and return JSON responses.\n",
        "\n",
        "  4. **formatter**\n",
        "     – Assemble **all** outputs into a single Markdown document.\n",
        "     – Include headings for Overview, API Documentation, Frontend Code, and Backend Code.\n",
        "\n",
        "Step 4: Output exactly this JSON (no extra keys):\n",
        "\n",
        "```json\n",
        "{{\n",
        "  \"scope_ok\": true,\n",
        "  \"optimized_query\": \"<one‑sentence restatement>\",\n",
        "  \"tech_stack\": {{\n",
        "    \"frontend\": \"<detected or default stack>\",\n",
        "    \"backend\":  \"<detected or default stack>\"\n",
        "  }},\n",
        "  \"prompts\": {{\n",
        "    \"api_docs\":  \"<instruction containing all required elements>\",\n",
        "    \"frontend\":  \"<instruction containing all required elements>\",\n",
        "    \"backend\":   \"<instruction containing all required elements>\",\n",
        "    \"formatter\": \"<instruction containing all required elements>\"\n",
        "  }}\n",
        "}}\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "b9Xn1yBwLkyi"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell sets up and runs the **Query Optimizer** agent:\n",
        "\n",
        "- **Imports & Client Setup**  \n",
        "  - `Agent`, `Task`, `Crew` from `crewai` to define and execute tasks.  \n",
        "  - `re` for stripping Markdown fences from the LLM output.  \n",
        "  - `OpenAI` client (v1 SDK) initialized with the Colab secret.  \n",
        "\n",
        "- **Agent Definition**  \n",
        "  - Creates `optimizer_agent` with role, goal, backstory, and LLM spec (`gpt-4o-mini`).  \n",
        "  - Defines a reusable `opt_task` template pointing at `OPTIMIZER_TEMPLATE`.  \n",
        "\n",
        "- **Helper Function `run_optimizer`**  \n",
        "  1. **Prompt Formatting**  \n",
        "     - Injects the `user_message` into the `OPTIMIZER_TEMPLATE`.  \n",
        "  2. **Task Execution**  \n",
        "     - Constructs and runs a one‑task `Crew` to invoke the optimizer.  \n",
        "  3. **Output Cleaning**  \n",
        "     - Strips any ```json fences.  \n",
        "  4. **JSON Parsing**  \n",
        "     - Returns a Python `dict` matching the optimizer’s schema.  \n",
        "\n",
        "- **Example Invocation**  \n",
        "  - Demonstrates using `run_optimizer(...)` to validate/normalize a sample user request.\n"
      ],
      "metadata": {
        "id": "98-QnuP185Hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from crewai import Agent, Task, Crew\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load API key from Colab secrets and initialize OpenAI client\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# 1) Define the Query Optimizer agent\n",
        "optimizer_agent = Agent(\n",
        "    role=\"Query Optimizer\",\n",
        "    goal=\"Validate scope and normalize user queries about Sikka APIs\",\n",
        "    backstory=\"Expert in Sikka’s API portfolio and software design.\",\n",
        "    allow_delegation=False,\n",
        "    llm=\"gpt-4o-mini\"\n",
        ")\n",
        "\n",
        "# 2) Prepare the optimization task template\n",
        "opt_task = Task(\n",
        "    agent=optimizer_agent,\n",
        "    description=OPTIMIZER_TEMPLATE,    # will .format(user_message=…) later\n",
        "    expected_output=\"JSON exactly matching the schema above.\"\n",
        ")\n",
        "\n",
        "def run_optimizer(user_message: str) -> dict:\n",
        "    \"\"\"\n",
        "    Execute the optimizer on `user_message` and parse its JSON output.\n",
        "    \"\"\"\n",
        "    # a) Inject the user's message into the template\n",
        "    prompt = OPTIMIZER_TEMPLATE.format(user_message=user_message)\n",
        "\n",
        "    # b) Create & run the task\n",
        "    task = Task(\n",
        "        agent=optimizer_agent,\n",
        "        description=prompt,\n",
        "        expected_output=\"JSON exactly matching the schema above.\"\n",
        "    )\n",
        "    crew_output = Crew(agents=[optimizer_agent], tasks=[task], verbose=False).kickoff()\n",
        "\n",
        "    # c) Extract raw LLM response\n",
        "    raw = crew_output.tasks_output[0].raw\n",
        "\n",
        "    # d) Strip any ``` or ```json fences\n",
        "    cleaned = \"\\n\".join(\n",
        "        line for line in raw.splitlines()\n",
        "        if not re.match(r\"^```(?:json)?\\s*$\", line)\n",
        "    ).strip()\n",
        "\n",
        "    # e) Parse and return as a dict\n",
        "    return json.loads(cleaned)\n",
        "\n",
        "# Example: Using the Query Optimizer on a user request\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Define the user's natural‑language request\n",
        "    user_request = (\n",
        "        \"I want a React checkout page that saves a patient's card \"\n",
        "        \"and runs a $25 sale using the Sikka sandbox.\"\n",
        "    )\n",
        "\n",
        "    # 2) Print the original request string\n",
        "    print(\"=== User Request ===\")\n",
        "    print(user_request, \"\\n\")\n",
        "\n",
        "    # 3) Run the optimizer to normalize & decompose the request\n",
        "    optimized_output = run_optimizer(user_request)\n",
        "\n",
        "    # 4) Pretty‑print the optimized result for clarity\n",
        "    import json\n",
        "    print(\"=== Optimizer Result ===\")\n",
        "    print(json.dumps(optimized_output, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2ILqBcFLlzS",
        "outputId": "9f2e42b3-fa16-466a-cf5c-fc3204fec4e6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== User Request ===\n",
            "I want a React checkout page that saves a patient's card and runs a $25 sale using the Sikka sandbox. \n",
            "\n",
            "=== Optimizer Result ===\n",
            "{\n",
            "  \"scope_ok\": true,\n",
            "  \"optimized_query\": \"Create a React checkout page that saves a patient's card and processes a $25 sale using the Sikka sandbox.\",\n",
            "  \"tech_stack\": {\n",
            "    \"frontend\": \"React + JavaScript\",\n",
            "    \"backend\": \"Node.js + Express + JavaScript\"\n",
            "  },\n",
            "  \"prompts\": {\n",
            "    \"api_docs\": \"Identify all required Sikka endpoints to create a checkout page that saves a patient's card and processes a sale. Include the full base URL and path for each endpoint, document the authentication flow that includes the request_key lifecycle, detail the required headers and body/query parameters per endpoint, and provide a sample request and sample response for each endpoint.\",\n",
            "    \"frontend\": \"Build the UI for the checkout page using React. Call the required endpoints from the API documentation. Specify the component/file names for the checkout, card input, and confirmation. Handle form state for input, loading indicators for API calls, and display errors if the transaction fails.\",\n",
            "    \"backend\": \"Implement server routes in Node.js using Express. Include code to request and refresh the request_key necessary for authentication. Show how to call each Sikka endpoint for saving the card and processing a sale, and ensure that the server returns appropriate JSON responses.\",\n",
            "    \"formatter\": \"Combine all outputs into one Markdown document. Include headings for Overview, API Documentation, Frontend Code, and Backend Code, ensuring clarity and structure for easy reading.\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell sets up and runs the “API‑Docs Generator” agent:\n",
        "\n",
        "- **Imports**  \n",
        "  - Pulls in `Agent`, `Task`, and `Crew` from `crewai` to define and execute the agent.  \n",
        "  - Imports `numpy` for array handling in the FAISS search.\n",
        "\n",
        "- **Context Retriever**  \n",
        "  - `retrieve_api_context(query, k)` embeds the user’s query, searches the FAISS index for the top‑k most relevant chunks, and concatenates them as a context string.\n",
        "\n",
        "- **Agent Definition**  \n",
        "  - `api_doc_agent` is configured to generate detailed Markdown API documentation for Sikka endpoints.\n",
        "\n",
        "- **Runner Function**  \n",
        "  - `run_api_docs_step(opt_out)`  \n",
        "    1. Checks if the user request is in‑scope.  \n",
        "    2. Builds a prompt combining the optimizer’s `api_docs` instruction with FAISS‑retrieved context.  \n",
        "    3. Runs a single‑task Crew to get the Markdown documentation.  \n",
        "    4. Returns the raw Markdown response for downstream use.\n"
      ],
      "metadata": {
        "id": "zV7RXdeY96bT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew   # Core classes to define and run our agent\n",
        "import numpy as np                    # Numerical library used by FAISS search\n",
        "\n",
        "def retrieve_api_context(query: str, k: int = 6) -> str:\n",
        "    \"\"\"\n",
        "    Embed the query, perform a FAISS similarity search,\n",
        "    and join the top-k document chunks into one context string.\n",
        "    \"\"\"\n",
        "    q_emb = embed_texts([query])[0]                      # 1) Create embedding for the query\n",
        "    _, idx = index.search(np.array([q_emb], dtype=\"float32\"), k)  # 2) Search FAISS index\n",
        "    # 3) Concatenate the retrieved passages with separators\n",
        "    return \"\\n\\n---\\n\\n\".join(docs[i][\"content\"] for i in idx[0])\n",
        "\n",
        "# Define the API‑Docs Generator agent\n",
        "api_doc_agent = Agent(\n",
        "    role             = \"API Docs Generator\",    # Agent’s persona\n",
        "    goal             = \"Produce detailed API documentation for the endpoints needed\",\n",
        "    backstory        = \"Specialist in Sikka API reference docs.\",\n",
        "    allow_delegation = False,\n",
        "    llm              = \"gpt-4o-mini\"\n",
        ")\n",
        "\n",
        "def run_api_docs_step(opt_out: dict) -> str:\n",
        "    \"\"\"\n",
        "    Build and run a single‑task Crew to generate Markdown API docs.\n",
        "    Returns the raw Markdown or an out‑of‑scope notice.\n",
        "    \"\"\"\n",
        "    # 1) Scope guard: skip if optimizer said out‑of‑scope\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return \"⚠️ Out of scope. No API docs generated.\"\n",
        "\n",
        "    # 2) Prepare prompt: instruction + retrieved context\n",
        "    instr  = opt_out[\"prompts\"][\"api_docs\"]                   # Optimizer’s API‑docs instruction\n",
        "    ctx    = retrieve_api_context(opt_out[\"optimized_query\"]) # FAISS context for the optimized query\n",
        "    prompt = f\"{instr}\\n\\nHere is the relevant API context:\\n{ctx}\"  # Complete LLM prompt\n",
        "\n",
        "    # 3) Define and run the Crew task\n",
        "    task = Task(\n",
        "        agent           = api_doc_agent,\n",
        "        description     = prompt,\n",
        "        expected_output = (\n",
        "            \"A Markdown document covering ONLY the Sikka endpoints, \"\n",
        "            \"authentication flow, headers, parameters, and sample calls.\"\n",
        "        )\n",
        "    )\n",
        "    crew_output = Crew(\n",
        "        agents=[api_doc_agent],\n",
        "        tasks=[task],\n",
        "        verbose=False\n",
        "    ).kickoff()  # Execute the task\n",
        "\n",
        "    # 4) Extract and return the raw Markdown response\n",
        "    return crew_output.tasks_output[0].raw\n"
      ],
      "metadata": {
        "id": "g-Csxg0uLsA1"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines and runs the “Frontend Code Generator” agent:\n",
        "\n",
        "- **Agent Definition**  \n",
        "  - Creates `frontend_agent` with a React/Next.js focus and clear UI/UX expertise.\n",
        "\n",
        "- **Runner Function (`run_frontend_step`)**  \n",
        "  1. **Scope Guard:** Returns early if the optimizer flagged the request as out‑of‑scope.  \n",
        "  2. **Prompt Assembly:** Combines the optimizer’s “frontend” instruction with the previously generated API docs.  \n",
        "  3. **Crew Execution:** Spins up a one‑task Crew to generate the React/Next.js code.  \n",
        "  4. **Output Extraction:** Returns the raw code string for use by subsequent steps.\n"
      ],
      "metadata": {
        "id": "Qp4bW7cg-GR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# 1) Define the Frontend Code Generator agent\n",
        "frontend_agent = Agent(\n",
        "    role             = \"Frontend Code Generator\",              # Agent’s persona\n",
        "    goal             = \"Produce React/Next.js frontend code for the checkout flow\",\n",
        "    backstory        = \"Expert in building modern React applications and UI/UX best practices.\",\n",
        "    allow_delegation = False,\n",
        "    llm              = \"gpt-4o-mini\"                         # Model to drive this agent\n",
        ")\n",
        "\n",
        "def run_frontend_step(opt_out: dict, api_docs_md: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate (or regenerate) the React/Next.js frontend code.\n",
        "\n",
        "    Args:\n",
        "      opt_out     – Output dict from run_optimizer(...)\n",
        "      api_docs_md – Markdown API docs from run_api_docs_step(...)\n",
        "\n",
        "    Returns:\n",
        "      Raw code string for the frontend application.\n",
        "    \"\"\"\n",
        "    # 1) Out‑of‑scope guard\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return \"⚠️ Out of scope. No frontend code generated.\"\n",
        "\n",
        "    # 2) Build the prompt using the optimizer’s 'frontend' instruction\n",
        "    instr  = opt_out[\"prompts\"][\"frontend\"]                   # Instruction text\n",
        "    prompt = (\n",
        "        f\"{instr}\\n\\nHere are the API docs you should integrate with:\\n\"\n",
        "        f\"{api_docs_md}\"\n",
        "    )\n",
        "\n",
        "    # 3) Launch a one‑task Crew to generate the code\n",
        "    task = Task(\n",
        "        agent           = frontend_agent,                     # Which agent to run\n",
        "        description     = prompt,                             # Full LLM prompt\n",
        "        expected_output = (\n",
        "            \"A React (or Next.js) component/file structure & code for the checkout UI, \"\n",
        "            \"handling card input, form state, loading, and error display.\"\n",
        "        )\n",
        "    )\n",
        "    crew_output = Crew(\n",
        "        agents=[frontend_agent],\n",
        "        tasks =[task],\n",
        "        verbose=False\n",
        "    ).kickoff()\n",
        "\n",
        "    # 4) Extract and return the raw code string\n",
        "    return crew_output.tasks_output[0].raw\n"
      ],
      "metadata": {
        "id": "7nO57VoDLtoe"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines and runs the “Backend Code Generator” agent:\n",
        "\n",
        "- **Agent Definition**  \n",
        "  - Creates `backend_agent` specialized in Node.js/Express APIs with a focus on security and scalability.\n",
        "\n",
        "- **Runner Function (`run_backend_step`)**  \n",
        "  1. **Scope Guard:** Checks the optimizer output; returns early if out‑of‑scope.  \n",
        "  2. **Prompt Assembly:** Combines the optimizer’s “backend” instruction with the generated API docs.  \n",
        "  3. **Crew Execution:** Launches a one‑task Crew to generate the Express server code.  \n",
        "  4. **Output Extraction:** Returns the raw backend code string for downstream use.  \n"
      ],
      "metadata": {
        "id": "WEQSxeY--Rpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# 1) Define the Backend Code Generator agent\n",
        "backend_agent = Agent(\n",
        "    role             = \"Backend Code Generator\",                 # Agent’s persona\n",
        "    goal             = \"Produce Node.js/Express backend code for the checkout flow\",\n",
        "    backstory        = \"Expert in building secure and scalable Express APIs.\",\n",
        "    allow_delegation = False,\n",
        "    llm              = \"gpt-4o-mini\"                          # Model to drive this agent\n",
        ")\n",
        "\n",
        "def run_backend_step(opt_out: dict, api_docs_md: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate the Node.js + Express backend code.\n",
        "\n",
        "    Args:\n",
        "      opt_out     – dict from run_optimizer(...)\n",
        "      api_docs_md – Markdown API docs from run_api_docs_step(...)\n",
        "\n",
        "    Returns:\n",
        "      Raw code string for the backend server.\n",
        "    \"\"\"\n",
        "    # 1) Out‑of‑scope guard\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return \"⚠️ Out of scope. No backend code generated.\"\n",
        "\n",
        "    # 2) Build the prompt using the optimizer’s 'backend' instruction\n",
        "    instr  = opt_out[\"prompts\"][\"backend\"]                      # Instruction text\n",
        "    prompt = (\n",
        "        f\"{instr}\\n\\nHere are the API docs you should integrate with:\\n\"\n",
        "        f\"{api_docs_md}\"\n",
        "    )\n",
        "\n",
        "    # 3) Launch a one‑task Crew to generate the code\n",
        "    task = Task(\n",
        "        agent           = backend_agent,                         # Which agent to run\n",
        "        description     = prompt,                                # Full LLM prompt\n",
        "        expected_output = (\n",
        "            \"Node.js + Express server code with routes to handle saving cards \"\n",
        "            \"and processing payments using the provided Sikka endpoints.\"\n",
        "        )\n",
        "    )\n",
        "    crew_output = Crew(\n",
        "        agents=[backend_agent],\n",
        "        tasks =[task],\n",
        "        verbose=False\n",
        "    ).kickoff()\n",
        "\n",
        "    # 4) Extract and return the raw code string\n",
        "    return crew_output.tasks_output[0].raw\n"
      ],
      "metadata": {
        "id": "U1kkqOVDLu68"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines the **Frontend Code Evaluator** agent and its runner function:\n",
        "\n",
        "- **Agent Definition**  \n",
        "  - `frontend_evaluator_agent` is a specialist in React/Next.js best practices and front‑end security.  \n",
        "  - Its sole responsibility is to detect **critical** correctness or security issues.\n",
        "\n",
        "- **Runner Helper (`run_frontend_eval`)**  \n",
        "  1. **Scope Check:** Returns empty report if the request is out of scope.  \n",
        "  2. **Prompt Construction:** Crafts a strict JSON‑only prompt asking for issues and suggestions.  \n",
        "  3. **Crew Execution:** Runs a single‑task Crew to evaluate the provided code.  \n",
        "  4. **Fence Stripping:** Removes any Markdown code fences from the LLM response.  \n",
        "  5. **JSON Parsing:** Parses and returns the structured report for downstream use.\n"
      ],
      "metadata": {
        "id": "yfbH6NWm-rhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# 1) Define the Frontend Evaluator agent\n",
        "frontend_evaluator_agent = Agent(\n",
        "    role             = \"Frontend Code Evaluator\",                  # Agent’s persona\n",
        "    goal             = (\n",
        "        \"Inspect the React/Next.js frontend code and report *only* critical \"\n",
        "        \"correctness or security issues in JSON format.\"\n",
        "    ),\n",
        "    backstory        = \"Expert in React best practices, form validation, and front‑end security.\",\n",
        "    allow_delegation = False,\n",
        "    llm              = \"gpt-4o-mini\"                               # Model to drive evaluation\n",
        ")\n",
        "\n",
        "# 2) Runner helper for frontend evaluation\n",
        "def run_frontend_eval(opt_out: dict, frontend_code: str) -> dict:\n",
        "    \"\"\"\n",
        "    Analyze frontend code for blocking issues and return a JSON report:\n",
        "    {\n",
        "      \"issues\": [ {\"location\":\"frontend\",\"line\":int,\"message\":str,\"severity\":\"critical\"}, ... ],\n",
        "      \"suggestions\": [ str, ... ]\n",
        "    }\n",
        "    \"\"\"\n",
        "    # Guard: skip evaluation if out-of-scope\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return {\"issues\": [], \"suggestions\": []}\n",
        "\n",
        "    # Build a strict JSON‑schema prompt\n",
        "    prompt = f\"\"\"\n",
        "You are a strict Bug‑Finder focused ONLY on frontend code.\n",
        "Report *only* critical correctness or security issues in this JSON schema:\n",
        "\n",
        "{{\n",
        "  \"issues\": [\n",
        "    {{\n",
        "      \"location\": \"frontend\",\n",
        "      \"line\": <integer>,\n",
        "      \"message\": \"<description>\",\n",
        "      \"severity\": \"critical\"\n",
        "    }},\n",
        "    ...\n",
        "  ],\n",
        "  \"suggestions\": [\n",
        "    \"<actionable improvement>\",\n",
        "    ...\n",
        "  ]\n",
        "}}\n",
        "\n",
        "Here is the frontend code to evaluate:\n",
        "{frontend_code}\n",
        "\n",
        "Do NOT include any markdown or additional keys—output only the JSON.\n",
        "\"\"\".strip()\n",
        "\n",
        "    # Execute the evaluation task\n",
        "    task = Task(\n",
        "        agent           = frontend_evaluator_agent,\n",
        "        description     = prompt,\n",
        "        expected_output = \"A JSON object with keys 'issues' and 'suggestions'.\"\n",
        "    )\n",
        "    out = Crew(agents=[frontend_evaluator_agent], tasks=[task], verbose=False).kickoff()\n",
        "    raw = out.tasks_output[0].raw                                 # Raw LLM reply\n",
        "\n",
        "    # Remove any ``` code fences\n",
        "    cleaned = \"\\n\".join(\n",
        "        line for line in raw.splitlines()\n",
        "        if not re.match(r\"^```(?:\\\\w+)?\\\\s*$\", line)\n",
        "    ).strip()\n",
        "\n",
        "    # Parse and return the JSON issue report\n",
        "    return json.loads(cleaned)\n"
      ],
      "metadata": {
        "id": "jLoK-cpvLwHF"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines the **Backend Code Evaluator** agent and its runner function:\n",
        "\n",
        "- **Agent Definition**  \n",
        "  - `backend_evaluator_agent` is an expert in Express API design, authentication flows, and security.  \n",
        "  - Its sole responsibility is to identify **critical** correctness or security issues in backend code.\n",
        "\n",
        "- **Runner Helper (`run_backend_eval`)**  \n",
        "  1. **Scope Check:** Returns an empty report if the request is out of scope.  \n",
        "  2. **Prompt Construction:** Builds a strict JSON‑only prompt asking for backend issues and suggestions.  \n",
        "  3. **Crew Execution:** Runs a single‑task Crew to evaluate the provided backend code.  \n",
        "  4. **Fence Stripping:** Removes any Markdown code fences from the LLM response.  \n",
        "  5. **JSON Parsing:** Parses and returns the structured report for use in the refinement pipeline.\n"
      ],
      "metadata": {
        "id": "3weYgEGG-xPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# 1) Define the Backend Evaluator agent\n",
        "backend_evaluator_agent = Agent(\n",
        "    role             = \"Backend Code Evaluator\",                     # Agent persona\n",
        "    goal             = (\n",
        "        \"Inspect the Node.js/Express backend code and report *only* critical \"\n",
        "        \"correctness or security issues in JSON format.\"\n",
        "    ),\n",
        "    backstory        = \"Expert in Express API design, authentication flows, and backend security.\",\n",
        "    allow_delegation = False,\n",
        "    llm              = \"gpt-4o-mini\"                                 # Model for evaluation\n",
        ")\n",
        "\n",
        "# 2) Runner helper for backend evaluation\n",
        "def run_backend_eval(opt_out: dict, backend_code: str) -> dict:\n",
        "    \"\"\"\n",
        "    Analyze backend code for blocking issues.\n",
        "    Returns a dict with:\n",
        "      {\n",
        "        \"issues\": [\n",
        "          {\"location\":\"backend\",\"line\":int,\"message\":str,\"severity\":\"critical\"},\n",
        "          ...\n",
        "        ],\n",
        "        \"suggestions\": [\n",
        "          str, ...\n",
        "        ]\n",
        "      }\n",
        "    \"\"\"\n",
        "    # Guard: skip if out-of-scope\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return {\"issues\": [], \"suggestions\": []}\n",
        "\n",
        "    # Build a strict JSON‑schema prompt\n",
        "    prompt = f\"\"\"\n",
        "You are a strict Bug‑Finder focused ONLY on backend code.\n",
        "Report *only* critical correctness or security issues in this JSON schema:\n",
        "\n",
        "{{\n",
        "  \"issues\": [\n",
        "    {{\n",
        "      \"location\": \"backend\",\n",
        "      \"line\": <integer>,\n",
        "      \"message\": \"<description>\",\n",
        "      \"severity\": \"critical\"\n",
        "    }},\n",
        "    ...\n",
        "  ],\n",
        "  \"suggestions\": [\n",
        "    \"<actionable improvement>\",\n",
        "    ...\n",
        "  ]\n",
        "}}\n",
        "\n",
        "Here is the backend code to evaluate:\n",
        "{backend_code}\n",
        "\n",
        "Do NOT include any markdown or additional keys—output only the JSON.\n",
        "\"\"\".strip()\n",
        "\n",
        "    # Execute the evaluation task\n",
        "    task = Task(\n",
        "        agent           = backend_evaluator_agent,\n",
        "        description     = prompt,\n",
        "        expected_output = \"A JSON object with keys 'issues' and 'suggestions'.\"\n",
        "    )\n",
        "    out = Crew(agents=[backend_evaluator_agent], tasks=[task], verbose=False).kickoff()\n",
        "    raw = out.tasks_output[0].raw                                  # Raw LLM reply\n",
        "\n",
        "    # Remove any ``` code fences\n",
        "    cleaned = \"\\n\".join(\n",
        "        line for line in raw.splitlines()\n",
        "        if not re.match(r\"^```(?:\\\\w+)?\\\\s*$\", line)\n",
        "    ).strip()\n",
        "\n",
        "    # Parse and return the JSON report\n",
        "    return json.loads(cleaned)\n"
      ],
      "metadata": {
        "id": "0nawYk5eLxFD"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines a **reusable Code Refinement Agent** and its helper function:\n",
        "\n",
        "- **Agent Definition**  \n",
        "  - `refine_agent` is an expert in iterative code improvement and best practices.  \n",
        "  - Its goal is to take evaluator feedback and produce a revised code snippet (frontend or backend) without any extra text.\n",
        "\n",
        "- **Runner Helper (`run_refine_step`)**  \n",
        "  1. **Scope Check:** Returns the original snippet if out of scope.  \n",
        "  2. **Feedback Preparation:** Converts suggestion strings into a bullet‑list (not used directly in prompt but illustrative).  \n",
        "  3. **Prompt Construction:** Includes the evaluator report and original code, asks for only the refined code.  \n",
        "  4. **Crew Execution:** Runs a single‑task Crew to generate the updated code.  \n",
        "  5. **Fence Stripping:** Removes any ``` code fences from the response.  \n",
        "  6. **Return:** Outputs the cleaned, refined code snippet.\n"
      ],
      "metadata": {
        "id": "_ERy8Wnj-3_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# 1) Define the Code Refinement Agent\n",
        "refine_agent = Agent(\n",
        "    role             = \"Code Refinement Agent\",        # Agent persona\n",
        "    goal             = (\n",
        "        \"Incorporate evaluator feedback into an existing code snippet \"\n",
        "        \"and return the revised code only.\"\n",
        "    ),\n",
        "    backstory        = \"Expert in iterative code improvement and best practices.\",\n",
        "    allow_delegation = False,                         # Keep tasks internal\n",
        "    llm              = \"gpt-4o-mini\"                  # Model to run refinements\n",
        ")\n",
        "\n",
        "def run_refine_step(\n",
        "    opt_out: dict,           # Output from the optimizer step\n",
        "    code_snippet: str,       # The code to refine (frontend or backend)\n",
        "    eval_report: dict,       # JSON with 'issues' and 'suggestions'\n",
        "    code_type: str           # \"frontend\" or \"backend\"\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Refine a code snippet by applying the evaluator's suggestions.\n",
        "    Returns only the updated code (no explanations).\n",
        "    \"\"\"\n",
        "    # 2) Out‑of‑scope guard\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return code_snippet\n",
        "\n",
        "    # 3) Build the prompt with evaluator report and original code\n",
        "    prompt = f\"\"\"\n",
        "You are a Code Refinement Agent. Update the following {code_type} code using the evaluator feedback.\n",
        "\n",
        "Evaluator Report:\n",
        "{json.dumps(eval_report, indent=2)}\n",
        "\n",
        "Original {code_type.capitalize()} Code:\n",
        "```\n",
        "{code_snippet}\n",
        "```\n",
        "\n",
        "Please return **only** the refined {code_type} code, applying all critical fixes. Do not include any explanations.\n",
        "\"\"\".strip()\n",
        "\n",
        "    # 4) Create and run the refinement task\n",
        "    task = Task(\n",
        "        agent           = refine_agent,\n",
        "        description     = prompt,\n",
        "        expected_output = f\"The updated {code_type} code snippet, with fixes applied.\"\n",
        "    )\n",
        "    crew_output = Crew(agents=[refine_agent], tasks=[task], verbose=False).kickoff()\n",
        "    raw = crew_output.tasks_output[0].raw  # LLM response\n",
        "\n",
        "    # 5) Strip any ``` code fences from the response\n",
        "    cleaned = \"\\n\".join(\n",
        "        line for line in raw.splitlines()\n",
        "        if not re.match(r\"^```(?:\\w+)?\\s*$\", line)\n",
        "    ).strip()\n",
        "\n",
        "    # 6) Return the cleaned, refined code\n",
        "    return cleaned\n"
      ],
      "metadata": {
        "id": "1RVUKkAZLyBk"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines the **parallelized end‑to‑end pipelines** for both frontend and backend:\n",
        "\n",
        "- **`_pipeline_frontend`**  \n",
        "  1. **Generate** initial React code  \n",
        "  2. **Evaluate** it for critical issues (prints debug report)  \n",
        "  3. **Refine** the code if any blocking issues are found  \n",
        "  4. **Return** the final, possibly refined frontend snippet  \n",
        "\n",
        "- **`_pipeline_backend`**  \n",
        "  1. **Generate** initial Express code  \n",
        "  2. **Evaluate** it for critical issues (prints debug report)  \n",
        "  3. **Refine** the code if needed  \n",
        "  4. **Return** the final backend snippet  \n",
        "\n",
        "- **`run_frontend_and_backend`**  \n",
        "  - Uses `ThreadPoolExecutor` to run both pipelines **concurrently**  \n",
        "  - Returns a tuple: `(final_frontend_code, final_backend_code)`  \n",
        "\n",
        "By parallelizing, this cell speeds up the combined generation‑evaluate‑refine workflow for both layers.\n"
      ],
      "metadata": {
        "id": "0UOaxYru_UuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def _pipeline_frontend(opt_out: dict, api_docs_md: str) -> str:\n",
        "    \"\"\"\n",
        "    Full frontend pipeline: generate → evaluate → refine.\n",
        "    Returns the final refined frontend code.\n",
        "    \"\"\"\n",
        "    # 1) Generate initial React/Next.js code\n",
        "    code = run_frontend_step(opt_out, api_docs_md)\n",
        "\n",
        "    # 2) Evaluate for critical issues\n",
        "    eval_report = run_frontend_eval(opt_out, code)\n",
        "    print(\"[DEBUG] Frontend eval_report:\", eval_report, flush=True)\n",
        "\n",
        "    # 3) Refine if any critical issues were reported\n",
        "    if eval_report[\"issues\"]:\n",
        "        code = run_refine_step(opt_out, code, eval_report, code_type=\"frontend\")\n",
        "\n",
        "    return code\n",
        "\n",
        "def _pipeline_backend(opt_out: dict, api_docs_md: str) -> str:\n",
        "    \"\"\"\n",
        "    Full backend pipeline: generate → evaluate → refine.\n",
        "    Returns the final refined backend code.\n",
        "    \"\"\"\n",
        "    # 1) Generate initial Node.js/Express code\n",
        "    code = run_backend_step(opt_out, api_docs_md)\n",
        "\n",
        "    # 2) Evaluate for critical issues\n",
        "    eval_report = run_backend_eval(opt_out, code)\n",
        "    print(\"[DEBUG] Backend eval_report:\", eval_report, flush=True)\n",
        "\n",
        "    # 3) Refine if any critical issues were reported\n",
        "    if eval_report[\"issues\"]:\n",
        "        code = run_refine_step(opt_out, code, eval_report, code_type=\"backend\")\n",
        "\n",
        "    return code\n",
        "\n",
        "def run_frontend_and_backend(opt_out: dict, api_docs_md: str) -> tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Execute both frontend and backend pipelines in parallel.\n",
        "    Returns a tuple: (final_frontend_code, final_backend_code).\n",
        "    \"\"\"\n",
        "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "        fut_frontend = executor.submit(_pipeline_frontend, opt_out, api_docs_md)\n",
        "        fut_backend  = executor.submit(_pipeline_backend,  opt_out, api_docs_md)\n",
        "\n",
        "        final_frontend = fut_frontend.result()\n",
        "        final_backend  = fut_backend.result()\n",
        "\n",
        "    return final_frontend, final_backend"
      ],
      "metadata": {
        "id": "lpT1UB2yLzGj"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell defines the **Formatter Agent** and its runner helper:\n",
        "\n",
        "- **`formatter_agent`**  \n",
        "  - An LLM agent tasked with assembling all pieces into one Markdown document  \n",
        "  - Has the role “Documentation Formatter” and a clear goal to produce sections in order  \n",
        "\n",
        "- **`run_formatter_step`**  \n",
        "  1. **Guard**: checks `scope_ok` before doing anything  \n",
        "  2. **Build Prompt**: embeds the optimized query, tech stack, API docs, frontend code, and backend code into a single instruction  \n",
        "  3. **Invoke** the `formatter_agent` via a one‑task `Crew`  \n",
        "  4. **Extract & Clean**: pulls out the raw Markdown and removes any accidental outer code fences  \n",
        "  5. **Return** the final Markdown string  \n",
        "\n",
        "With this, the system produces a cohesive document containing Overview, API Documentation, Frontend Code, and Backend Code sections.\n"
      ],
      "metadata": {
        "id": "vLn5I6f0_hCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# 1) Define the Formatter Agent\n",
        "formatter_agent = Agent(\n",
        "    role             = \"Documentation Formatter\",  # Agent’s title\n",
        "    goal             = (                             # What it must achieve\n",
        "        \"Assemble the optimized query, tech stack, API docs, frontend code, \"\n",
        "        \"and backend code into one coherent Markdown document.\"\n",
        "    ),\n",
        "    backstory        = \"Detail‑oriented technical writer and developer.\",\n",
        "    allow_delegation = False,                       # Don’t split into sub‑agents\n",
        "    llm              = \"gpt-4o-mini\"                # Model to use\n",
        ")\n",
        "\n",
        "def run_formatter_step(\n",
        "    opt_out: dict,\n",
        "    api_docs_md: str,\n",
        "    frontend_code: str,\n",
        "    backend_code: str\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Takes optimizer output plus API docs, frontend, and backend code,\n",
        "    and returns a single Markdown document with the correct sections.\n",
        "    \"\"\"\n",
        "    # Guard: only proceed if the original query was in‑scope\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return \"⚠️ Out of scope. Nothing to format.\"\n",
        "\n",
        "    # Build the instruction for the agent, injecting all pieces\n",
        "    prompt = f\"\"\"\n",
        "You are the Documentation Formatter. Using the pieces below, produce **only**\n",
        "a Markdown document with these top‑level headings in this order:\n",
        "\n",
        "# Overview\n",
        "# API Documentation\n",
        "# Frontend Code\n",
        "# Backend Code\n",
        "\n",
        "### Overview\n",
        "**Task:** {opt_out['optimized_query']}\n",
        "**Tech Stack:**\n",
        "- Frontend: {opt_out['tech_stack']['frontend']}\n",
        "- Backend: {opt_out['tech_stack']['backend']}\n",
        "\n",
        "### API Documentation\n",
        "{api_docs_md}\n",
        "\n",
        "### Frontend Code\n",
        "```javascript\n",
        "{frontend_code}\n",
        "```\n",
        "### Backend Code\n",
        "```javascript\n",
        "{backend_code}\n",
        "```\n",
        "Return only the Markdown—no extra commentary. \"\"\".strip()\n",
        "\n",
        "    # Create the formatting task\n",
        "    task = Task(\n",
        "        agent           = formatter_agent,\n",
        "        description     = prompt,\n",
        "        expected_output = \"A single Markdown document with the specified sections.\"\n",
        "    )\n",
        "    # Run the agent\n",
        "    crew_output = Crew(agents=[formatter_agent], tasks=[task], verbose=False).kickoff()\n",
        "\n",
        "    # Extract the raw Markdown response\n",
        "    md = crew_output.tasks_output[0].raw\n",
        "\n",
        "    # If the LLM wrapped everything in ``` fences, remove them\n",
        "    if md.startswith(\"```\"):\n",
        "        md = \"\\n\".join(line for line in md.splitlines() if not re.match(r\"^```\", line)).strip()\n",
        "\n",
        "    return md\n"
      ],
      "metadata": {
        "id": "AOjIMfm4PO0J"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell ties together the entire Sikka checkout AI pipeline and provides a CLI‑style entry point:\n",
        "\n",
        "- **`orchestrate(user_message)`**  \n",
        "  1. **Optimize** the user’s request into a structured plan (`opt_out`).  \n",
        "  2. **Generate API docs** based on that plan, showing only the first 300 characters as a snippet.  \n",
        "  3. **Produce & auto‑fix** both frontend and backend code in parallel, printing short snippets.  \n",
        "  4. **Format** all pieces into one cohesive Markdown document (`final_md`).  \n",
        "  5. **Return** the final Markdown (or an out‑of‑scope notice).\n",
        "\n",
        "- **Debug prints** at each stage help you trace progress in Colab or your terminal.\n",
        "\n",
        "- **`if __name__ == \"__main__\"`** block demonstrates how to call `orchestrate` directly when running the script, printing the complete output.\n",
        "\n",
        "With this cell, you can run the full end‑to‑end flow in one call and see live debug output for each step.\n"
      ],
      "metadata": {
        "id": "ldTXJg3m__e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def orchestrate(user_message: str) -> str:\n",
        "    \"\"\"\n",
        "    Runs the full Sikka checkout pipeline:\n",
        "      1) Optimize the user query\n",
        "      2) Generate API docs\n",
        "      3) Generate & auto‑fix frontend + backend code\n",
        "      4) Format everything into Markdown\n",
        "\n",
        "    Returns the final Markdown (or an out‑of‑scope notice).\n",
        "    \"\"\"\n",
        "    # 1) Optimize: parse and structure the user’s request\n",
        "    opt_out = run_optimizer(user_message)\n",
        "    print(\"🔍 Optimizer Output:\", opt_out, \"\\n\" + \"─\" * 60, flush=True)\n",
        "    # If out of scope, immediately return notice\n",
        "    if not opt_out.get(\"scope_ok\", False):\n",
        "        return f\"⚠️ Out of scope: {opt_out.get('reason','')}\"\n",
        "\n",
        "    # 2) API docs: generate documentation and show a snippet\n",
        "    api_docs = run_api_docs_step(opt_out)\n",
        "    print(\"📄 API Documentation (snippet):\", api_docs[:300], \"\\n\" + \"─\" * 60, flush=True)\n",
        "\n",
        "    # 3) Code gen & refinement: run both pipelines in parallel\n",
        "    frontend_code, backend_code = run_frontend_and_backend(opt_out, api_docs)\n",
        "    print(\"🚀 Frontend Code (snippet):\", frontend_code[:200], flush=True)\n",
        "    print(\"🔧 Backend  Code (snippet):\", backend_code[:200], \"\\n\" + \"─\" * 60, flush=True)\n",
        "\n",
        "    # 4) Formatting: assemble all parts into final Markdown\n",
        "    final_md = run_formatter_step(opt_out, api_docs, frontend_code, backend_code)\n",
        "    print(\"🎉 Final Markdown generated.\", flush=True)\n",
        "\n",
        "    # Return the complete Markdown document\n",
        "    return final_md\n",
        "\n",
        "# ── Example usage ───────────────────────────────────────────\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample user request to kick off the pipeline\n",
        "    message = (\n",
        "        \"I want a React checkout page that saves a patient's card \"\n",
        "        \"and runs a $25 sale using Sikka sandbox.\"\n",
        "    )\n",
        "    # Run orchestration and print the result\n",
        "    doc = orchestrate(message)\n",
        "    print(\"\\n=== Final Output ===\\n\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UrpwDkgL1Kx",
        "outputId": "bdf2d7f1-7a48-4e25-aeb8-3ba402ed9fcc"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Optimizer Output: {'scope_ok': True, 'optimized_query': \"Create a React checkout page that saves a patient's card and processes a $25 sale using the Sikka API sandbox.\", 'tech_stack': {'frontend': 'React + JavaScript', 'backend': 'Node.js + Express + JavaScript'}, 'prompts': {'api_docs': \"Identify required Sikka endpoints for patient card storage and sale processing: 1. Save Card: Full URL: https://api.sikkasoft.com/v4/save_card, Method: POST, Required headers: Authorization: Bearer <token>, Content-Type: application/json; Body: { 'patient_id': <id>, 'card_info': { 'number': <number>, 'expiry': <date>, 'cvc': <cvc> } }; Sample Request: POST to /save_card with body containing patient_id and card_info; Sample Response: { 'status': 'success', 'message': 'Card saved' }. 2. Process Sale: Full URL: https://api.sikkasoft.com/v4/process_sale, Method: POST, Required headers: Authorization: Bearer <token>, Content-Type: application/json; Body: { 'patient_id': <id>, 'amount': 25 }; Sample Request: POST to /process_sale with body containing patient_id and amount; Sample Response: { 'status': 'success', 'transaction_id': <id> }.\", 'frontend': 'Create a React component named CheckoutPage.js; Use React Hook Form for form handling of patient card data and payment amount; Call the save card endpoint upon form submission; Display loading state during API calls and error messages on failed responses; Organize components into directories, e.g., /components/CheckoutPage.js.', 'backend': \"In Node.js with Express, set up route handlers for /api/save_card and /api/process_sale; Include middleware for token management (get and refresh request_key); Use Axios or Fetch to make requests to the Sikka API, handling responses and returning JSON; Example code: app.post('/api/save_card', async (req, res) => { ... });\", 'formatter': 'Assemble outputs into a Markdown document with sections: ## Overview, ## API Documentation (including details for each endpoint), ## Frontend Code (including component structure and React code sample), ## Backend Code (including Express route handler code sample).'}} \n",
            "────────────────────────────────────────────────────────────\n",
            "📄 API Documentation (snippet): # Sikka API Documentation for Patient Card Storage and Sale Processing\n",
            "\n",
            "## Overview\n",
            "\n",
            "The Sikka Payments API allows healthcare practices to securely process payments through an API. This documentation outlines the necessary endpoints for storing patient card information and processing sales.\n",
            "\n",
            "## Base \n",
            "────────────────────────────────────────────────────────────\n",
            "[DEBUG] Backend eval_report: {'issues': [{'location': 'backend', 'line': 29, 'message': 'Token fetching logic does not consider token expiration or refreshing token logic; it only checks if token is empty.', 'severity': 'critical'}, {'location': 'backend', 'line': 38, 'message': 'No validation for input data (patient_id, card_info) in /api/save_card endpoint; can lead to security issues such as SQL injection or malformed requests.', 'severity': 'critical'}, {'location': 'backend', 'line': 50, 'message': 'No validation for input data (patient_id, amount) in /api/process_sale endpoint; can lead to security issues such as SQL injection or malformed requests.', 'severity': 'critical'}, {'location': 'backend', 'line': 5, 'message': \"The token stored in memory (variable 'token') is not secure; it may lead to security issues if the server is restarted.\", 'severity': 'critical'}], 'suggestions': ['Implement token expiration check and refresh logic to ensure the token is valid for each request.', 'Use a validation library (e.g., Joi) to validate incoming request data for both endpoints.', 'Consider using a secure storage method for the token instead of an in-memory variable; possibly use an environment variable or a more secure vault solution.', 'Implement rate limiting and logging for sensitive endpoints to enhance security and track suspicious activity.']}\n",
            "[DEBUG] Frontend eval_report: {'issues': [{'location': 'frontend', 'line': 56, 'message': 'The API token is hardcoded, exposing sensitive information. It should not be included directly in the frontend code.', 'severity': 'critical'}, {'location': 'frontend', 'line': 32, 'message': 'The card number, expiry, and CVC fields are not validated for format or length, which may lead to incorrect data being sent to the API.', 'severity': 'critical'}], 'suggestions': ['Use environment variables to manage sensitive information like API tokens and do not hardcode them in the frontend code.', 'Implement input validation for credit card fields enforcing format checks for card number, expiry date, and CVC before submission.']}\n",
            "🚀 Frontend Code (snippet): import { useState } from 'react';\n",
            "\n",
            "const useCheckout = () => {\n",
            "  const [loading, setLoading] = useState(false);\n",
            "  const [error, setError] = useState(null);\n",
            "\n",
            "  const saveCard = async (data, token) => {\n",
            "🔧 Backend  Code (snippet): const express = require('express');\n",
            "const axios = require('axios');\n",
            "const bodyParser = require('body-parser');\n",
            "const Joi = require('joi');\n",
            "const app = express();\n",
            "const PORT = process.env.PORT || 3000; \n",
            "────────────────────────────────────────────────────────────\n",
            "🎉 Final Markdown generated.\n",
            "\n",
            "=== Final Output ===\n",
            "\n",
            "# Overview\n",
            "**Task:** Create a React checkout page that saves a patient's card and processes a $25 sale using the Sikka API sandbox.  \n",
            "**Tech Stack:**\n",
            "- Frontend: React + JavaScript\n",
            "- Backend: Node.js + Express + JavaScript\n",
            "\n",
            "# API Documentation\n",
            "## Sikka API Documentation for Patient Card Storage and Sale Processing\n",
            "\n",
            "### Overview\n",
            "\n",
            "The Sikka Payments API allows healthcare practices to securely process payments through an API. This documentation outlines the necessary endpoints for storing patient card information and processing sales.\n",
            "\n",
            "### Base URLs\n",
            "\n",
            "- **Production:** [https://api.sikkasoft.com/v2/payment](https://api.sikkasoft.com/v2/payment)\n",
            "- **Sandbox:** [https://api.sikkasoft.com/v2/sandbox/payment](https://api.sikkasoft.com/v2/sandbox/payment)\n",
            "\n",
            "### Authentication\n",
            "\n",
            "All requests to the Sikka Payments API must include the following headers for authentication:\n",
            "\n",
            "- **Authorization:** `Bearer <token>`\n",
            "- **Content-Type:** `application/json`\n",
            "\n",
            "### Endpoints\n",
            "\n",
            "#### 1. Save Card\n",
            "\n",
            "- **Endpoint:** `POST https://api.sikkasoft.com/v4/save_card`\n",
            "  \n",
            "##### Request Headers\n",
            "Authorization: Bearer <token>\n",
            "Content-Type: application/json\n",
            "\n",
            "##### Request Body\n",
            "{\n",
            "   \"patient_id\": \"<id>\",\n",
            "   \"card_info\": {\n",
            "      \"number\": \"<number>\",\n",
            "      \"expiry\": \"<date>\",\n",
            "      \"cvc\": \"<cvc>\"\n",
            "   }\n",
            "}\n",
            "\n",
            "##### Sample Request\n",
            "POST /save_card\n",
            "{\n",
            "   \"patient_id\": \"12345\",\n",
            "   \"card_info\": {\n",
            "      \"number\": \"4111111111111111\",\n",
            "      \"expiry\": \"2029-04\",\n",
            "      \"cvc\": \"123\"\n",
            "   }\n",
            "}\n",
            "\n",
            "##### Sample Response\n",
            "{\n",
            "   \"status\": \"success\",\n",
            "   \"message\": \"Card saved\"\n",
            "}\n",
            "\n",
            "---\n",
            "\n",
            "#### 2. Process Sale\n",
            "\n",
            "- **Endpoint:** `POST https://api.sikkasoft.com/v4/process_sale`\n",
            "  \n",
            "##### Request Headers\n",
            "Authorization: Bearer <token>\n",
            "Content-Type: application/json\n",
            "\n",
            "##### Request Body\n",
            "{\n",
            "   \"patient_id\": \"<id>\",\n",
            "   \"amount\": 25\n",
            "}\n",
            "\n",
            "##### Sample Request\n",
            "POST /process_sale\n",
            "{\n",
            "   \"patient_id\": \"12345\",\n",
            "   \"amount\": 25\n",
            "}\n",
            "\n",
            "##### Sample Response\n",
            "{\n",
            "   \"status\": \"success\",\n",
            "   \"transaction_id\": \"<id>\"\n",
            "}\n",
            "\n",
            "### Additional Endpoints\n",
            "\n",
            "#### 3. Sale by Saved Card\n",
            "\n",
            "- **Endpoint:** `POST https://api.sikkasoft.com/v2/payment/sale`\n",
            "  \n",
            "##### Request Headers\n",
            "Content-Type: application/json\n",
            "\n",
            "##### Request Body\n",
            "{\n",
            "    \"request_key\": \"<request_key>\",\n",
            "    \"transaction_media\": \"billing_id\",\n",
            "    \"patient_id\": \"<patient_id>\",\n",
            "    \"guarantor_id\": \"<guarantor_id>\",\n",
            "    \"practice_id\": \"<practice_id>\",\n",
            "    \"cust_id\": \"<cust_id>\",\n",
            "    \"provider_id\": \"<provider_id>\",\n",
            "    \"name\": \"<name>\",\n",
            "    \"zipcode\": \"<zipcode>\",\n",
            "    \"transaction_amount\": \"<transaction_amount>\"\n",
            "}\n",
            "\n",
            "##### Sample Response\n",
            "{\n",
            "    \"items\": [\n",
            "        {\n",
            "            \"transaction_id\": \"039-0012684312\",\n",
            "            \"transaction_amount\": \"35.75\",\n",
            "            \"transaction_status\": \"approved\",\n",
            "            \"billing_id\": \"60xx9H\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "\n",
            "#### 4. Retrieve Saved Card\n",
            "\n",
            "- **Endpoint:** `GET https://api.sikkasoft.com/v2/payment/store_card`\n",
            "\n",
            "##### Query Parameters\n",
            "request_key={request_key}&\n",
            "patient_id={patient_id}&\n",
            "guarantor_id={guarantor_id}&\n",
            "practice_id={practice_id}&\n",
            "startdate={startdate}&\n",
            "enddate={enddate}&\n",
            "billing_id={billing_id}&\n",
            "name={name}&\n",
            "card_number={card_number}&\n",
            "transaction_status={transaction_status}&\n",
            "is_active={is_active}&\n",
            "is_recurring_payments={is_recurring_payments}\n",
            "\n",
            "##### Sample Response\n",
            "{\n",
            "    \"items\": [\n",
            "        {\n",
            "            \"billing_id\": \"60EV9H\",\n",
            "            \"card_number_masked\": \"1111\",\n",
            "            \"expiration_month\": \"04\",\n",
            "            \"expiration_year\": \"2029\",\n",
            "            \"name\": \"Mia Elson\",\n",
            "            \"zipcode\": \"95121\",\n",
            "            \"is_active\": \"true\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "\n",
            "#### 5. Save a Card\n",
            "\n",
            "- **Endpoint:** `POST https://api.sikkasoft.com/v2/payment/store_card`\n",
            "\n",
            "##### Request Body\n",
            "{\n",
            "    \"request_key\": \"<request_key>\",\n",
            "    \"patient_id\": \"<patient_id>\",\n",
            "    \"guarantor_id\": \"<guarantor_id>\",\n",
            "    \"practice_id\": \"<practice_id>\",\n",
            "    \"cust_id\": \"<cust_id>\",\n",
            "    \"provider_id\": \"<provider_id>\",\n",
            "    \"name\": \"<name>\",\n",
            "    \"zipcode\": \"<zipcode>\",\n",
            "    \"card_number\": \"<card_number>\",\n",
            "    \"expiration_month\": \"<expiration_month>\",\n",
            "    \"expiration_year\": \"<expiration_year>\"\n",
            "}\n",
            "\n",
            "##### Sample Response\n",
            "{\n",
            "    \"items\": [\n",
            "        {\n",
            "            \"transaction_id\": \"039-0012428197\",\n",
            "            \"billing_id\": \"60EV88\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "\n",
            "### Compliance\n",
            "\n",
            "- Ensure all requests handling credit card data are made in a PCI-compliant manner.\n",
            "- For testing, use the sandbox environment for secure experimentation.\n",
            "\n",
            "### Conclusion\n",
            "\n",
            "Utilizing the Sikka Payments API, healthcare practices can efficiently manage patient card storage and payment processing. Consult the provided documentation for detailed API interaction guidelines, including required headers, parameters, and examples for common API calls.\n",
            "\n",
            "# Frontend Code\n",
            "import { useState } from 'react';\n",
            "\n",
            "const useCheckout = () => {\n",
            "  const [loading, setLoading] = useState(false);\n",
            "  const [error, setError] = useState(null);\n",
            "\n",
            "  const saveCard = async (data, token) => {\n",
            "    setLoading(true);\n",
            "    setError(null);\n",
            "\n",
            "    try {\n",
            "      const response = await fetch('https://api.sikkasoft.com/v4/save_card', {\n",
            "        method: 'POST',\n",
            "        headers: {\n",
            "          'Authorization': `Bearer ${token}`,\n",
            "          'Content-Type': 'application/json',\n",
            "        },\n",
            "        body: JSON.stringify(data),\n",
            "      });\n",
            "\n",
            "      if (!response.ok) {\n",
            "        throw new Error('Failed to save card. Please check your input.');\n",
            "      }\n",
            "\n",
            "      const result = await response.json();\n",
            "      return result;\n",
            "    } catch (err) {\n",
            "      setError(err.message);\n",
            "    } finally {\n",
            "      setLoading(false);\n",
            "    }\n",
            "  };\n",
            "\n",
            "  return { saveCard, loading, error };\n",
            "};\n",
            "\n",
            "export default useCheckout;\n",
            "\n",
            "import React from 'react';\n",
            "import { useForm } from 'react-hook-form';\n",
            "import useCheckout from '../hooks/useCheckout';\n",
            "\n",
            "const CheckoutPage = () => {\n",
            "  const { register, handleSubmit, formState: { errors } } = useForm();\n",
            "  const { saveCard, loading, error } = useCheckout();\n",
            "\n",
            "  const onSubmit = async (data) => {\n",
            "    const token = process.env.REACT_APP_API_TOKEN; // Use environment variable for the token\n",
            "    const cardData = {\n",
            "      patient_id: data.patient_id,\n",
            "      card_info: {\n",
            "        number: data.card_number,\n",
            "        expiry: data.expiry,\n",
            "        cvc: data.cvc,\n",
            "      },\n",
            "    };\n",
            "\n",
            "    const result = await saveCard(cardData, token);\n",
            "    if (result) {\n",
            "      alert(result.message || 'Card saved successfully!');\n",
            "    }\n",
            "  };\n",
            "\n",
            "  return (\n",
            "    <div className=\"checkout-container\">\n",
            "      <h1>Checkout</h1>\n",
            "      <form onSubmit={handleSubmit(onSubmit)}>\n",
            "        <div>\n",
            "          <label htmlFor=\"patient_id\">Patient ID:</label>\n",
            "          <input\n",
            "            {...register('patient_id', { required: true })}\n",
            "            type=\"text\"\n",
            "            id=\"patient_id\"\n",
            "          />\n",
            "          {errors.patient_id && <span>This field is required</span>}\n",
            "        </div>\n",
            "\n",
            "        <div>\n",
            "          <label htmlFor=\"card_number\">Card Number:</label>\n",
            "          <input\n",
            "            {...register('card_number', { required: true, pattern: /^[0-9]{16}$/, maxLength: 16 })}\n",
            "            type=\"text\"\n",
            "            id=\"card_number\"\n",
            "          />\n",
            "          {errors.card_number && <span>Invalid card number</span>}\n",
            "        </div>\n",
            "\n",
            "        <div>\n",
            "          <label htmlFor=\"expiry\">Expiry (MM/YYYY):</label>\n",
            "          <input\n",
            "            {...register('expiry', { required: true, pattern: /^(0[1-9]|1[0-2])\\/\\d{4}$/ })}\n",
            "            type=\"text\"\n",
            "            id=\"expiry\"\n",
            "          />\n",
            "          {errors.expiry && <span>Invalid expiry date</span>}\n",
            "        </div>\n",
            "\n",
            "        <div>\n",
            "          <label htmlFor=\"cvc\">CVC:</label>\n",
            "          <input\n",
            "            {...register('cvc', { required: true, pattern: /^[0-9]{3}$/, maxLength: 3 })}\n",
            "            type=\"text\"\n",
            "            id=\"cvc\"\n",
            "          />\n",
            "          {errors.cvc && <span>Invalid CVC</span>}\n",
            "        </div>\n",
            "\n",
            "        <button type=\"submit\" disabled={loading}>\n",
            "          {loading ? 'Processing...' : 'Save Card'}\n",
            "        </button>\n",
            "        \n",
            "        {error && <p className=\"error-message\">{error}</p>}\n",
            "      </form>\n",
            "    </div>\n",
            "  );\n",
            "};\n",
            "\n",
            "export default CheckoutPage;\n",
            "# Backend Code\n",
            "const express = require('express');\n",
            "const axios = require('axios');\n",
            "const bodyParser = require('body-parser');\n",
            "const Joi = require('joi');\n",
            "const app = express();\n",
            "const PORT = process.env.PORT || 3000;\n",
            "\n",
            "app.use(bodyParser.json());\n",
            "\n",
            "const SIKKA_BASE_URL = 'https://api.sikkasoft.com/v4'; // Change to sandbox URL if needed\n",
            "let token = ''; // Variable to store the token\n",
            "let tokenExpiry = null; // Variable to store token expiration timestamp\n",
            "\n",
            "// Middleware for fetching and refreshing the request key\n",
            "const tokenManagementMiddleware = async (req, res, next) => {\n",
            "    if (!token || (tokenExpiry && Date.now() >= tokenExpiry)) {\n",
            "        try {\n",
            "            const response = await axios.post('https://api.sikkasoft.com/v2/token', {\n",
            "                // Include necessary fields to get the token\n",
            "                // client_id: '<client_id>',\n",
            "                // client_secret: '<client_secret>',\n",
            "            });\n",
            "            token = response.data.token; // Assuming the token field name is 'token'\n",
            "            tokenExpiry = Date.now() + response.data.expires_in * 1000; // Assuming the expires_in field is in seconds\n",
            "        } catch (error) {\n",
            "            console.error('Error fetching token', error);\n",
            "            return res.status(500).json({ error: 'Error fetching token' });\n",
            "        }\n",
            "    }\n",
            "    req.token = token; // Attach token to request so it can be used in route handlers\n",
            "    next();\n",
            "};\n",
            "\n",
            "// Input validation schemas\n",
            "const saveCardSchema = Joi.object({\n",
            "    patient_id: Joi.string().required(),\n",
            "    card_info: Joi.object().required()\n",
            "});\n",
            "\n",
            "const processSaleSchema = Joi.object({\n",
            "    patient_id: Joi.string().required(),\n",
            "    amount: Joi.number().positive().required()\n",
            "});\n",
            "\n",
            "// Save Card endpoint\n",
            "app.post('/api/save_card', tokenManagementMiddleware, async (req, res) => {\n",
            "    const { error } = saveCardSchema.validate(req.body);\n",
            "    if (error) return res.status(400).json({ error: error.details[0].message });\n",
            "\n",
            "    const { patient_id, card_info } = req.body;\n",
            "\n",
            "    try {\n",
            "        const response = await axios.post(`${SIKKA_BASE_URL}/save_card`, {\n",
            "            patient_id,\n",
            "            card_info\n",
            "        }, {\n",
            "            headers: {\n",
            "                Authorization: `Bearer ${req.token}`,\n",
            "                'Content-Type': 'application/json'\n",
            "            }\n",
            "        });\n",
            "\n",
            "        res.json(response.data);\n",
            "    } catch (error) {\n",
            "        console.error('Error saving card:', error);\n",
            "        res.status(500).json({ error: 'Error saving card' });\n",
            "    }\n",
            "});\n",
            "\n",
            "// Process Sale endpoint\n",
            "app.post('/api/process_sale', tokenManagementMiddleware, async (req, res) => {\n",
            "    const { error } = processSaleSchema.validate(req.body);\n",
            "    if (error) return res.status(400).json({ error: error.details[0].message });\n",
            "\n",
            "    const { patient_id, amount } = req.body;\n",
            "\n",
            "    try {\n",
            "        const response = await axios.post(`${SIKKA_BASE_URL}/process_sale`, {\n",
            "            patient_id,\n",
            "            amount\n",
            "        }, {\n",
            "            headers: {\n",
            "                Authorization: `Bearer ${req.token}`,\n",
            "                'Content-Type': 'application/json'\n",
            "            }\n",
            "        });\n",
            "\n",
            "        res.json(response.data);\n",
            "    } catch (error) {\n",
            "        console.error('Error processing sale:', error);\n",
            "        res.status(500).json({ error: 'Error processing sale' });\n",
            "    }\n",
            "});\n",
            "\n",
            "// Start the server\n",
            "app.listen(PORT, () => {\n",
            "    console.log(`Server is running on port ${PORT}`);\n",
            "});\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Summary**\n",
        "\n",
        "This cell implements a simple chat interface with memory and context retrieval:\n",
        "\n",
        "- **`conversation` list**  \n",
        "  - Keeps full history of user and assistant messages for follow‑up continuity.\n",
        "\n",
        "- **`chat_with_memory(question: str) -> str`**  \n",
        "  1. Appends the new user question to `conversation`.  \n",
        "  2. Retrieves relevant API docs passages from FAISS via `retrieve_api_context`.  \n",
        "  3. Constructs `system_messages` including:  \n",
        "     - Instructions to use only provided docs.  \n",
        "     - The full final Markdown doc (`doc`).  \n",
        "     - The FAISS‑retrieved passages.  \n",
        "  4. Combines `system_messages` with the entire `conversation` history.  \n",
        "  5. Sends the batch to the LLM (`gpt-4o-mini`) and obtains the assistant reply.  \n",
        "  6. Appends and returns the assistant’s answer.\n",
        "\n",
        "- **Example usage**  \n",
        "  - Runs three follow‑up questions, printing each answer.  \n",
        "  - Finally pretty‑prints the full `conversation` history.\n",
        "\n",
        "This enables iterative Q&A over the generated documentation and code, maintaining context across turns.\n"
      ],
      "metadata": {
        "id": "q6y82W5OALUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = []\n",
        "\n",
        "def chat_with_memory(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Ask a follow‑up question, using both the final Markdown doc and\n",
        "    vector‑retrieved context. Maintains full conversation history.\n",
        "    \"\"\"\n",
        "    # 1) Add the new user message to the history\n",
        "    conversation.append({\"role\": \"user\", \"content\": question})\n",
        "\n",
        "    # 2) Retrieve relevant chunks from your FAISS index\n",
        "    vector_ctx = retrieve_api_context(question)\n",
        "\n",
        "    # 3) Build the system + history messages\n",
        "    system_messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": (\n",
        "                \"You are an expert on Sikka API integrations. \"\n",
        "                \"Use ONLY the documentation and relevant passages provided to answer.\"\n",
        "            )\n",
        "        },\n",
        "        {\"role\": \"system\", \"content\": f\"Full Documentation:\\n\\n{doc}\"},\n",
        "        {\"role\": \"system\", \"content\": f\"Relevant Passages:\\n\\n{vector_ctx}\"}\n",
        "    ]\n",
        "\n",
        "    # 4) Combine all messages: system directives + prior conversation\n",
        "    messages = system_messages + conversation\n",
        "\n",
        "    # 5) Query the model\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages\n",
        "    )\n",
        "    answer = response.choices[0].message.content\n",
        "\n",
        "    # 6) Append the assistant’s answer to the history and return it\n",
        "    conversation.append({\"role\": \"assistant\", \"content\": answer})\n",
        "    return answer\n",
        "\n",
        "# Example usage:\n",
        "q1 = \"What headers do I need for the payment endpoint?\"\n",
        "print(\"A1:\", chat_with_memory(q1))\n",
        "\n",
        "q2 = \"And how do I refresh the request_key in my server code?\"\n",
        "print(\"A2:\", chat_with_memory(q2))\n",
        "\n",
        "q3 = \"How should the UI handle rate‑limit errors?\"\n",
        "print(\"A3:\", chat_with_memory(q3))\n",
        "\n",
        "# Finally, inspect the conversation history:\n",
        "import pprint\n",
        "print(\"\\n=== Conversation History ===\")\n",
        "pprint.pprint(conversation)"
      ],
      "metadata": {
        "id": "nIDp3DlVidme"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next Steps\n",
        "\n",
        "- **Extract core pipeline functions**  \n",
        "  Consolidate `run_optimizer`, `run_api_docs_step`, `run_frontend_step`, `run_backend_step`, `run_formatter_step`, and `chat_with_memory` into a standalone module (e.g. `ai_pipeline.py`).\n",
        "\n",
        "- **Build a backend endpoint**  \n",
        "  Create an Express route that accepts user messages, invokes the AI pipeline functions, and returns JSON or Markdown responses.\n",
        "\n",
        "- **Develop a React chatbot UI**  \n",
        "  Scaffold a simple React app with a chat interface that sends user input to your backend and displays streaming or batched AI responses.\n",
        "\n",
        "- **Centralize configuration & secrets**  \n",
        "  Move API keys, model names, and other settings into a `.env` (or equivalent) and load via `dotenv` or environment variables.\n",
        "\n",
        "- **Add testing**  \n",
        "  Write unit tests that mock the AI calls, plus integration tests that spin up your backend and verify end‑to‑end behavior.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5B6HUJ2cmEYw"
      }
    }
  ]
}